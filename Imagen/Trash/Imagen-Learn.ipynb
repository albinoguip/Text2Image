{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3ee864-31d7-48ef-b59c-01b9685a3b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Imagen(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        unets,\n",
    "        *,\n",
    "        image_sizes,                                # for cascading ddpm, image size at each stage\n",
    "        text_encoder_name = DEFAULT_T5_NAME,\n",
    "        text_embed_dim = None,\n",
    "        channels = 3,\n",
    "        timesteps = 1000,\n",
    "        cond_drop_prob = 0.1,\n",
    "        loss_type = 'l2',\n",
    "        noise_schedules = 'cosine',\n",
    "        pred_objectives = 'noise',\n",
    "        lowres_noise_schedule = 'linear',\n",
    "        lowres_sample_noise_level = 0.2,            # in the paper, they present a new trick where they noise the lowres conditioning image, and at sample time, fix it to a certain level (0.1 or 0.3) - the unets are also made to be conditioned on this noise level\n",
    "        per_sample_random_aug_noise_level = False,  # unclear when conditioning on augmentation noise level, whether each batch element receives a random aug noise value - turning off due to @marunine's find\n",
    "        condition_on_text = True,\n",
    "        auto_normalize_img = True,                  # whether to take care of normalizing the image from [0, 1] to [-1, 1] and back automatically - you can turn this off if you want to pass in the [-1, 1] ranged image yourself from the dataloader\n",
    "        continuous_times = True,\n",
    "        p2_loss_weight_gamma = 0.5,                 # p2 loss weight, from https://arxiv.org/abs/2204.00227 - 0 is equivalent to weight of 1 across time\n",
    "        p2_loss_weight_k = 1,\n",
    "        dynamic_thresholding = True,\n",
    "        dynamic_thresholding_percentile = 0.9,      # unsure what this was based on perusal of paper\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        # loss\n",
    "\n",
    "        if loss_type == 'l1':\n",
    "            loss_fn = F.l1_loss\n",
    "        elif loss_type == 'l2':\n",
    "            loss_fn = F.mse_loss\n",
    "        elif loss_type == 'huber':\n",
    "            loss_fn = F.smooth_l1_loss\n",
    "        else:\n",
    "            raise NotImplementedError()\n",
    "\n",
    "        self.loss_type = loss_type\n",
    "        self.loss_fn = loss_fn\n",
    "\n",
    "        # conditioning hparams\n",
    "\n",
    "        self.condition_on_text = condition_on_text\n",
    "        self.unconditional = not condition_on_text\n",
    "\n",
    "        # channels\n",
    "\n",
    "        self.channels = channels\n",
    "\n",
    "        # automatically take care of ensuring that first unet is unconditional\n",
    "        # while the rest of the unets are conditioned on the low resolution image produced by previous unet\n",
    "\n",
    "        unets = cast_tuple(unets)\n",
    "        num_unets = len(unets)\n",
    "\n",
    "        # determine noise schedules per unet\n",
    "\n",
    "        timesteps = cast_tuple(timesteps, num_unets)\n",
    "\n",
    "        # make sure noise schedule defaults to 'cosine', 'cosine', and then 'linear' for rest of super-resoluting unets\n",
    "\n",
    "        noise_schedules = cast_tuple(noise_schedules)\n",
    "        noise_schedules = pad_tuple_to_length(noise_schedules, 2, 'cosine')\n",
    "        noise_schedules = pad_tuple_to_length(noise_schedules, num_unets, 'linear')\n",
    "\n",
    "        # construct noise schedulers\n",
    "\n",
    "        noise_scheduler_klass = GaussianDiffusion if not continuous_times else GaussianDiffusionContinuousTimes\n",
    "        self.noise_schedulers = nn.ModuleList([])\n",
    "\n",
    "        for timestep, noise_schedule in zip(timesteps, noise_schedules):\n",
    "            noise_scheduler = noise_scheduler_klass(noise_schedule = noise_schedule, timesteps = timestep)\n",
    "            self.noise_schedulers.append(noise_scheduler)\n",
    "\n",
    "        # lowres augmentation noise schedule\n",
    "\n",
    "        self.lowres_noise_schedule = GaussianDiffusionContinuousTimes(noise_schedule = lowres_noise_schedule)\n",
    "\n",
    "        # ddpm objectives - predicting noise by default\n",
    "\n",
    "        self.pred_objectives = cast_tuple(pred_objectives, num_unets)\n",
    "\n",
    "        # get text encoder\n",
    "\n",
    "        self.text_encoder_name = text_encoder_name\n",
    "        self.text_embed_dim = default(text_embed_dim, lambda: get_encoded_dim(text_encoder_name))\n",
    "\n",
    "        # construct unets\n",
    "\n",
    "        self.unets = nn.ModuleList([])\n",
    "\n",
    "        for ind, one_unet in enumerate(unets):\n",
    "            assert isinstance(one_unet, Unet)\n",
    "            is_first = ind == 0\n",
    "\n",
    "            one_unet = one_unet.cast_model_parameters(\n",
    "                lowres_cond = not is_first,\n",
    "                cond_on_text = self.condition_on_text,\n",
    "                text_embed_dim = self.text_embed_dim if self.condition_on_text else None,\n",
    "                channels = self.channels,\n",
    "                channels_out = self.channels,\n",
    "                learned_sinu_pos_emb = continuous_times\n",
    "            )\n",
    "\n",
    "            self.unets.append(one_unet)\n",
    "\n",
    "        # unet image sizes\n",
    "\n",
    "        self.image_sizes = cast_tuple(image_sizes)\n",
    "        assert num_unets == len(image_sizes), f'you did not supply the correct number of u-nets ({len(self.unets)}) for resolutions {image_sizes}'\n",
    "\n",
    "        self.sample_channels = cast_tuple(self.channels, num_unets)\n",
    "\n",
    "        # cascading ddpm related stuff\n",
    "\n",
    "        lowres_conditions = tuple(map(lambda t: t.lowres_cond, self.unets))\n",
    "        assert lowres_conditions == (False, *((True,) * (num_unets - 1))), 'the first unet must be unconditioned (by low resolution image), and the rest of the unets must have `lowres_cond` set to True'\n",
    "\n",
    "        self.lowres_sample_noise_level = lowres_sample_noise_level\n",
    "        self.per_sample_random_aug_noise_level = per_sample_random_aug_noise_level\n",
    "\n",
    "        # classifier free guidance\n",
    "\n",
    "        self.cond_drop_prob = cond_drop_prob\n",
    "        self.can_classifier_guidance = cond_drop_prob > 0.\n",
    "\n",
    "        # normalize and unnormalize image functions\n",
    "\n",
    "        self.normalize_img = normalize_neg_one_to_one if auto_normalize_img else identity\n",
    "        self.unnormalize_img = unnormalize_zero_to_one if auto_normalize_img else identity\n",
    "\n",
    "        # dynamic thresholding\n",
    "\n",
    "        self.dynamic_thresholding = cast_tuple(dynamic_thresholding, num_unets)\n",
    "        self.dynamic_thresholding_percentile = dynamic_thresholding_percentile\n",
    "\n",
    "        # p2 loss weight\n",
    "\n",
    "        self.p2_loss_weight_k = p2_loss_weight_k\n",
    "        self.p2_loss_weight_gamma = cast_tuple(p2_loss_weight_gamma, num_unets)\n",
    "\n",
    "        assert all([(gamma_value <= 2) for gamma_value in self.p2_loss_weight_gamma]), 'in paper, they noticed any gamma greater than 2 is harmful'\n",
    "\n",
    "        # one temp parameter for keeping track of device\n",
    "\n",
    "        self.register_buffer('_temp', torch.tensor([0.]), persistent = False)\n",
    "\n",
    "        # default to device of unets passed in\n",
    "\n",
    "        self.to(next(self.unets.parameters()).device)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2432836-46bd-4608-8f2d-9b9a203775ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exists(val):\n",
    "    return val is not None\n",
    "\n",
    "def identity(t, *args, **kwargs):\n",
    "    return t\n",
    "\n",
    "def maybe(fn):\n",
    "    @wraps(fn)\n",
    "    def inner(x):\n",
    "        if not exists(x):\n",
    "            return x\n",
    "        return fn(x)\n",
    "    return inner\n",
    "\n",
    "def default(val, d):\n",
    "    if exists(val):\n",
    "        return val\n",
    "    return d() if callable(d) else d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a06e8df-6de9-4993-98aa-72539ef82652",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cast_tuple(val, length = None):\n",
    "    if isinstance(val, list):\n",
    "        val = tuple(val)\n",
    "\n",
    "    output = val if isinstance(val, tuple) else ((val,) * default(length, 1))\n",
    "\n",
    "    if exists(length):\n",
    "        assert len(output) == length\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838e4fc0-c924-46bb-8824-7365ea6a3403",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_tuple_to_length(t, length, fillvalue = None):\n",
    "    remain_length = length - len(t)\n",
    "    if remain_length <= 0:\n",
    "        return t\n",
    "    return (*t, *((fillvalue,) * remain_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0e23e9-ee75-4f2f-8e88-fdf1866be57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_schedules = 'cosine'\n",
    "num_unets       = 4\n",
    "\n",
    "noise_schedules = cast_tuple(noise_schedules)\n",
    "print(noise_schedules)\n",
    "noise_schedules = pad_tuple_to_length(noise_schedules, 2, 'cosine')\n",
    "print(noise_schedules)\n",
    "noise_schedules = pad_tuple_to_length(noise_schedules, num_unets, 'linear')\n",
    "print(noise_schedules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6a940f-82b1-4ad3-92a2-b4ec7e587018",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_schedules = 'cosine'\n",
    "# noise_schedules = (noise_schedules,)\n",
    "print(noise_schedules)\n",
    "noise_schedules = (noise_schedules, 'cosine')\n",
    "print(noise_schedules)\n",
    "n_unets = 4\n",
    "mults = n_unets - len(noise_schedules) if n_unets - len(noise_schedules) > 0 else 0\n",
    "noise_schedules = (*noise_schedules, *('linear',)*mults)\n",
    "print(noise_schedules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9135c18d-4d1a-4e0e-9361-c91d3a0b4123",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from ComplexModels import UNet\n",
    "from GaussianDiffusion import GaussianDiffusion\n",
    "from TextEncoder import TextEncoderT5Based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6310691-c953-47d1-8d73-a738ffdd9473",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_neg_one_to_one(img):\n",
    "    return img * 2 - 1\n",
    "\n",
    "def unnormalize_zero_to_one(normed_img):\n",
    "    return (normed_img + 1) * 0.5\n",
    "\n",
    "def resize_image_to(image, target_image_size):\n",
    "    orig_image_size = image.shape[-1]\n",
    "\n",
    "    if orig_image_size == target_image_size:\n",
    "        return image\n",
    "\n",
    "    scale_factors = target_image_size / orig_image_size\n",
    "    return resize(image, scale_factors = scale_factors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bb1ef54a-53c1-4766-90d6-6c78e69d7df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Imagen(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        unets,\n",
    "        *,\n",
    "        image_sizes,                                # for cascading ddpm, image size at each stage\n",
    "        text_encoder_name = 'google/t5-v1_1-small',\n",
    "        text_embed_dim = None,\n",
    "        channels = 3,\n",
    "        timesteps = 1000,\n",
    "        cond_drop_prob = 0.1,\n",
    "        loss_type = 'l2',\n",
    "        noise_schedules = 'cosine',\n",
    "        pred_objectives = 'noise',\n",
    "        lowres_noise_schedule = 'linear',\n",
    "        lowres_sample_noise_level = 0.2,            # in the paper, they present a new trick where they noise the lowres conditioning image, and at sample time, fix it to a certain level (0.1 or 0.3) - the unets are also made to be conditioned on this noise level\n",
    "        per_sample_random_aug_noise_level = False,  # unclear when conditioning on augmentation noise level, whether each batch element receives a random aug noise value - turning off due to @marunine's find\n",
    "        condition_on_text = True,\n",
    "        auto_normalize_img = True,                  # whether to take care of normalizing the image from [0, 1] to [-1, 1] and back automatically - you can turn this off if you want to pass in the [-1, 1] ranged image yourself from the dataloader\n",
    "        continuous_times = True,\n",
    "        p2_loss_weight_gamma = 0.5,                 # p2 loss weight, from https://arxiv.org/abs/2204.00227 - 0 is equivalent to weight of 1 across time\n",
    "        p2_loss_weight_k = 1,\n",
    "        dynamic_thresholding = True,\n",
    "        dynamic_thresholding_percentile = 0.9,      # unsure what this was based on perusal of paper\n",
    "    ):\n",
    "        super(Imagen, self).__init__()\n",
    "        \n",
    "        # loss\n",
    "\n",
    "        self.loss_type   = 'l2'\n",
    "        self.loss_fn     = F.mse_loss\n",
    "        self.channels    = channels\n",
    "        self.image_sizes = image_sizes\n",
    "\n",
    "        # conditioning hparams\n",
    "\n",
    "        self.condition_on_text, self.unconditional = True, False   \n",
    "        \n",
    "        self.lowres_sample_noise_level         = lowres_sample_noise_level\n",
    "        self.per_sample_random_aug_noise_level = per_sample_random_aug_noise_level # False\n",
    "\n",
    "        n_unets   = len(unets)\n",
    "        timesteps = (timesteps,)*n_unets  \n",
    "        \n",
    "        noise_schedules = (noise_schedules, 'cosine')\n",
    "        mults           = n_unets - len(noise_schedules) if n_unets - len(noise_schedules) > 0 else 0\n",
    "        noise_schedules = (*noise_schedules, *('linear',)*mults)\n",
    "\n",
    "        self.lowres_noise_schedule = GaussianDiffusion(noise_type=lowres_noise_schedule)\n",
    "        self.pred_objectives       = (pred_objectives,)*n_unets\n",
    "\n",
    "        self.text_encoder_name = text_encoder_name\n",
    "        self.text_embed_dim    = TextEncoderT5Based(text_encoder_name).embed_dim\n",
    "        self.text_encoder      = TextEncoderT5Based(text_encoder_name)     \n",
    "\n",
    "        self.noise_schedulers = nn.ModuleList([])\n",
    "        for timestep, noise_schedule in zip(timesteps, noise_schedules):\n",
    "            noise_scheduler = GaussianDiffusion(noise_type=noise_schedule, timesteps=timestep)\n",
    "            self.noise_schedulers.append(noise_scheduler)\n",
    "            \n",
    "        self.unets = nn.ModuleList([])        \n",
    "        for i, current_unet in enumerate(unets):\n",
    "            self.unets.append(current_unet.lowres_change(lowres_cond = not (i == 0)))\n",
    "\n",
    "        self.sample_channels = (self.channels,)*n_unets\n",
    "\n",
    "        lowres_conditions = tuple([t.lowres_cond for t in self.unets])\n",
    "        # assert lowres_conditions == (False, *((True,) * (n_unets - 1)))\n",
    "\n",
    "        self.cond_drop_prob          = cond_drop_prob\n",
    "        self.can_classifier_guidance = cond_drop_prob > 0.\n",
    "\n",
    "        self.normalize_img   = normalize_neg_one_to_one  # if auto_normalize_img else identity\n",
    "        self.unnormalize_img = unnormalize_zero_to_one   # if auto_normalize_img else identity\n",
    "\n",
    "\n",
    "        self.dynamic_thresholding            = (dynamic_thresholding,)*n_unets\n",
    "        self.dynamic_thresholding_percentile = dynamic_thresholding_percentile\n",
    "\n",
    "        self.p2_loss_weight_k     = p2_loss_weight_k\n",
    "        self.p2_loss_weight_gamma = (p2_loss_weight_gamma,)*n_unets\n",
    "\n",
    "        self.register_buffer('_temp', torch.tensor([0.]), persistent = False)\n",
    "\n",
    "        self.to(next(self.unets.parameters()).device)\n",
    "        \n",
    "    @property\n",
    "    def device(self):\n",
    "        return self._temp.device\n",
    "\n",
    "    def get_unet(self, unet_number):\n",
    "        assert 0 < unet_number <= len(self.unets)\n",
    "        index = unet_number - 1\n",
    "        return self.unets[index]\n",
    "\n",
    "    @contextmanager\n",
    "    def one_unet_in_gpu(self, unet_number = None, unet = None):\n",
    "        assert exists(unet_number) ^ exists(unet)\n",
    "\n",
    "        if exists(unet_number):\n",
    "            unet = self.get_unet(unet_number)\n",
    "\n",
    "        self.cuda()\n",
    "\n",
    "        devices = [module_device(unet) for unet in self.unets]\n",
    "        self.unets.cpu()\n",
    "        unet.cuda()\n",
    "\n",
    "        yield\n",
    "\n",
    "        for unet, device in zip(self.unets, devices):\n",
    "            unet.to(device)\n",
    "\n",
    "            \n",
    "    # ========================================================================================================\n",
    "    # ========================================================================================================\n",
    "    # ========================================================================================================\n",
    "    # ========================================================================================================\n",
    "    \n",
    "    def p_mean_variance(self, unet, x, t, noise_scheduler, text_embeds = None, text_mask = None,\n",
    "                        cond_images = None, lowres_cond_img = None, lowres_noise_times = None,\n",
    "                        cond_scale = 1., model_output = None, t_next = None, pred_objective = 'noise',\n",
    "                        dynamic_threshold = True):\n",
    "        # False = False or True\n",
    "        assert not (cond_scale != 1. and not self.can_classifier_guidance), 'imagen was not trained with conditional dropout, and thus one cannot use classifier free guidance (cond_scale anything other than 1)'\n",
    "\n",
    "        pred = default(model_output, lambda: unet.forward_with_cond_scale(x, noise_scheduler.get_condition(t), text_embeds = text_embeds, text_mask = text_mask, cond_images = cond_images, cond_scale = cond_scale, lowres_cond_img = lowres_cond_img, lowres_noise_times = self.lowres_noise_schedule.get_condition(lowres_noise_times)))\n",
    "\n",
    "        if pred_objective == 'noise':\n",
    "            x_start = noise_scheduler.predict_start_from_noise(x, t = t, noise = pred)\n",
    "        elif pred_objective == 'x_start':\n",
    "            x_start = pred\n",
    "        else:\n",
    "            raise ValueError(f'unknown objective {pred_objective}')\n",
    "\n",
    "        if dynamic_threshold:\n",
    "            # following pseudocode in appendix\n",
    "            # s is the dynamic threshold, determined by percentile of absolute values of reconstructed sample per batch element\n",
    "            s = torch.quantile(\n",
    "                rearrange(x_start, 'b ... -> b (...)').abs(),\n",
    "                self.dynamic_thresholding_percentile,\n",
    "                dim = -1\n",
    "            )\n",
    "\n",
    "            s.clamp_(min = 1.)\n",
    "            s = right_pad_dims_to(x_start, s)\n",
    "            x_start = x_start.clamp(-s, s) / s\n",
    "        else:\n",
    "            x_start.clamp_(-1., 1.)\n",
    "\n",
    "        return noise_scheduler.q_posterior(x_start = x_start, x_t = x, t = t, t_next = t_next)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9172e077-1a7f-4dc5-8993-dadbf2702362",
   "metadata": {},
   "outputs": [],
   "source": [
    "unet1 = UNet(dim = 8, cond_dim = 40, text_embed_dim = 40, dim_mults = (1, 2, 4, 8), num_resnet_blocks = 3,\n",
    "             layer_attns = (False, True, True, True), layer_cross_attns = (False, True, True, True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3748f462-fd13-49a9-ae8c-816837845155",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ComplexModels.UNet"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(unet1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0b09aaa7-a81f-4e1b-87b4-571f085289b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unet1.lowres_cond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c46120-b3ac-4040-8659-ac94e14dad1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Imagen((unet1,),\n",
    "        image_sizes=(32,),                                # for cascading ddpm, image size at each stage\n",
    "        text_encoder_name = 'google/t5-v1_1-small',\n",
    "        text_embed_dim = None,\n",
    "        channels = 3,\n",
    "        timesteps = 1000,\n",
    "        cond_drop_prob = 0.1,\n",
    "        loss_type = 'l2',\n",
    "        noise_schedules = 'cosine',\n",
    "        pred_objectives = 'noise',\n",
    "        lowres_noise_schedule = 'linear',\n",
    "        lowres_sample_noise_level = 0.2,            # in the paper, they present a new trick where they noise the lowres conditioning image, and at sample time, fix it to a certain level (0.1 or 0.3) - the unets are also made to be conditioned on this noise level\n",
    "        per_sample_random_aug_noise_level = False,  # unclear when conditioning on augmentation noise level, whether each batch element receives a random aug noise value - turning off due to @marunine's find\n",
    "        condition_on_text = True,\n",
    "        auto_normalize_img = True,                  # whether to take care of normalizing the image from [0, 1] to [-1, 1] and back automatically - you can turn this off if you want to pass in the [-1, 1] ranged image yourself from the dataloader\n",
    "        continuous_times = True,\n",
    "        p2_loss_weight_gamma = 0.5,                 # p2 loss weight, from https://arxiv.org/abs/2204.00227 - 0 is equivalent to weight of 1 across time\n",
    "        p2_loss_weight_k = 1,\n",
    "        dynamic_thresholding = True,\n",
    "        dynamic_thresholding_percentile = 0.9,      # unsure what this was based on perusal of paper\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ee2501-aa9e-4d3a-b9a8-50bba8bdaa06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lowers_change(self, lowres_cond):\n",
    "    \n",
    "        if lowres_cond == self.lowres_cond:\n",
    "            return self\n",
    "        return self.__class__(**{**self._locals, **dict(lowres_cond = lowres_cond)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4487f04-ee3b-488a-919e-da1980c865fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_mean_variance(self, unet, x, t, noise_scheduler, \n",
    "                    \n",
    "                        text_embeds = None, text_mask = None,\n",
    "                        cond_images = None, lowres_cond_img = None, lowres_noise_times = None,\n",
    "                        cond_scale = 1., model_output = None, t_next = None, pred_objective = 'noise',\n",
    "                        dynamic_threshold = True):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6909e9c2-71ee-4ca2-b0dd-c3e394af709f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_sample(self, unet, x, t, *, noise_scheduler,\n",
    "             \n",
    "             t_next = None, text_embeds = None, text_mask = None,\n",
    "             cond_images = None, cond_scale = 1., lowres_cond_img = None, lowres_noise_times = None,\n",
    "             pred_objective = 'noise', dynamic_threshold = True):\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b59f83-fac6-4100-b71a-cace83eefb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_sample_loop(self, unet, shape, *, noise_scheduler, \n",
    "                  \n",
    "                  lowres_cond_img = None,\n",
    "                  lowres_noise_times = None, text_embeds = None, text_mask = None, cond_images = None,\n",
    "                  cond_scale = 1, pred_objective = 'noise', dynamic_threshold = True):\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d932d7-86c7-41f3-a42e-fad5c7138d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(\n",
    "        self,\n",
    "        texts: List[str] = None,\n",
    "        text_masks = None,\n",
    "        text_embeds = None,\n",
    "        cond_images = None,\n",
    "        batch_size = 1,\n",
    "        cond_scale = 1.,\n",
    "        lowres_sample_noise_level = None,\n",
    "        stop_at_unet_number = None,\n",
    "        return_all_unet_outputs = False,\n",
    "        return_pil_images = False,\n",
    "        device = None,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0c51bb-5ec7-4067-b848-a67f0c997a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_losses(self, unet, x_start, times, *, noise_scheduler,\n",
    "         lowres_cond_img = None, lowres_aug_times = None, text_embeds = None,\n",
    "         text_mask = None, cond_images = None, noise = None, times_next = None,\n",
    "         pred_objective = 'noise', p2_loss_weight_gamma = 0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d74526-ca62-4a59-bd8c-2f5b84a1e929",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_image_to(image, target_image_size):\n",
    "    orig_image_size = image.shape[-1]\n",
    "\n",
    "    if orig_image_size == target_image_size:\n",
    "        return image\n",
    "\n",
    "    scale_factors = target_image_size / orig_image_size\n",
    "    return resize(image, scale_factors = scale_factors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2fe08d-04e0-4fd7-9e62-d9127e629651",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9206140b-583c-4daf-aae2-5b23da3a2b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(self, images, texts: List[str], unet_number, cond_images = None):  \n",
    "\n",
    "        unet_index = unet_number - 1        \n",
    "        unet       = self.unets[unet_index]\n",
    "\n",
    "        noise_scheduler      = self.noise_schedulers[unet_index]\n",
    "        p2_loss_weight_gamma = self.p2_loss_weight_gamma[unet_index]\n",
    "        pred_objective       = self.pred_objectives[unet_index]\n",
    "        target_image_size    = self.image_sizes[unet_index]\n",
    "        prev_image_size      = self.image_sizes[unet_index - 1] if unet_index > 0 else None\n",
    "        b, c, h, w, device,  = *images.shape, images.device\n",
    "\n",
    "        times = noise_scheduler.sample_random_times(b, device = device)\n",
    "\n",
    "        text_embeds, text_masks = self.text_encoder(texts)\n",
    "        text_embeds = tuple([t.to(images.device) for t in text_embeds])\n",
    "        text_masks  = tuple([t.to(images.device) for t in text_masks])\n",
    "\n",
    "        assert not (text_embeds.shape[-1] != self.text_embed_dim), f'invalid text embedding dimension'\n",
    "\n",
    "        lowres_cond_img = lowres_aug_times = None\n",
    "        if prev_image_size is not None:      \n",
    "            lowres_cond_img = resize_image_to(resize_image_to(images, prev_image_size), target_image_size)\n",
    "            lowres_aug_time = repeat(self.lowres_noise_schedule.sample_random_times(1, device = device), '1 -> b', b = b)\n",
    "\n",
    "\n",
    "        images = resize_image_to(images, target_image_size)\n",
    "        \n",
    "        '''p_losses(self, unet, x_start, times, text_embeds = None, text_mask = None, cond_images = None,\n",
    "                    noise_scheduler,\n",
    "                    lowres_cond_img = None, lowres_aug_times = None, \n",
    "                    ### noise = None, times_next = None,\n",
    "                    pred_objective = 'noise', p2_loss_weight_gamma = 0.)'''\n",
    "\n",
    "        return self.p_losses(unet, images, times, text_embeds=text_embeds, text_mask=text_masks,cond_images=cond_images,\n",
    "                             noise_scheduler = noise_scheduler,\n",
    "                             lowres_cond_img = lowres_cond_img, lowres_aug_times = lowres_aug_times,\n",
    "                             pred_objective = pred_objective, p2_loss_weight_gamma = p2_loss_weight_gamma)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c728ef9-89a6-4028-9e35-3e8813c44575",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = default(noise, lambda: torch.randn_like(x_start))\n",
    "\n",
    "        # normalize to [-1, 1]\n",
    "\n",
    "        x_start = self.normalize_img(x_start)\n",
    "        lowres_cond_img = maybe(self.normalize_img)(lowres_cond_img)\n",
    "\n",
    "        # get x_t\n",
    "\n",
    "        x_noisy, log_snr = noise_scheduler.q_sample(x_start = x_start, t = times, noise = noise)\n",
    "\n",
    "        # also noise the lowres conditioning image\n",
    "        # at sample time, they then fix the noise level of 0.1 - 0.3\n",
    "\n",
    "        lowres_cond_img_noisy = None\n",
    "        if exists(lowres_cond_img):\n",
    "            lowres_aug_times = default(lowres_aug_times, times)\n",
    "            lowres_cond_img_noisy, _ = self.lowres_noise_schedule.q_sample(x_start = lowres_cond_img, t = lowres_aug_times, noise = torch.randn_like(lowres_cond_img))\n",
    "\n",
    "        # get prediction\n",
    "\n",
    "        pred = unet.forward(\n",
    "            x_noisy,\n",
    "            noise_scheduler.get_condition(times),\n",
    "            text_embeds = text_embeds,\n",
    "            text_mask = text_mask,\n",
    "            cond_images = cond_images,\n",
    "            lowres_noise_times = self.lowres_noise_schedule.get_condition(lowres_aug_times),\n",
    "            lowres_cond_img = lowres_cond_img_noisy,\n",
    "            cond_drop_prob = self.cond_drop_prob,\n",
    "        )\n",
    "\n",
    "        # prediction objective\n",
    "\n",
    "        if pred_objective == 'noise':\n",
    "            target = noise\n",
    "        elif pred_objective == 'x_start':\n",
    "            target = x_start\n",
    "        else:\n",
    "            raise ValueError(f'unknown objective {pred_objective}')\n",
    "\n",
    "        # losses\n",
    "\n",
    "        losses = self.loss_fn(pred, target, reduction = 'none')\n",
    "        losses = reduce(losses, 'b ... -> b', 'mean')\n",
    "\n",
    "        # p2 loss reweighting\n",
    "\n",
    "        if p2_loss_weight_gamma > 0:\n",
    "            loss_weight = (self.p2_loss_weight_k + log_snr.exp()) ** -p2_loss_weight_gamma\n",
    "            losses = losses * loss_weight\n",
    "\n",
    "        return losses.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06141d99-55ac-41f6-85ea-29c58834150d",
   "metadata": {},
   "outputs": [],
   "source": [
    "    p_losses(self, unet, x_start, times, text_embeds = None, text_mask = None, cond_images = None,\n",
    "             noise_scheduler,\n",
    "             lowres_cond_img = None, lowres_aug_times = None, \n",
    "             ### noise = None, times_next = None,\n",
    "             pred_objective = 'noise', p2_loss_weight_gamma = 0.):\n",
    "        \n",
    "        \n",
    "        noise = noise if noise is not None else torch.randn_like(x_start)\n",
    "        noise = default(noise, lambda: )\n",
    "\n",
    "        # get x_t\n",
    "        x_start          = self.normalize_img(x_start)\n",
    "        x_noisy, log_snr = noise_scheduler.q_sample(x_start = x_start, t = times, noise = noise)\n",
    "        \n",
    "        lowres_cond_img_noisy = None\n",
    "        if lowres_cond_img is not None:      \n",
    "            lowres_cond_img  = self.normalize_img(lowres_cond_img)            \n",
    "            lowres_aug_times = lowres_aug_times if lowres_aug_times is not None else times\n",
    "            \n",
    "            lowres_cond_img_noisy, _ = self.lowres_noise_schedule.q_sample(x_start = lowres_cond_img, t = lowres_aug_times, noise = torch.randn_like(lowres_cond_img))\n",
    "            \n",
    "        pred = unet.forward(x_noisy,\n",
    "                            noise_scheduler.get_condition(times),\n",
    "                            text_embeds = text_embeds,\n",
    "                            text_mask = text_mask)         \n",
    "                            '''cond_images = cond_images,\n",
    "                            lowres_noise_times = self.lowres_noise_schedule.get_condition(lowres_aug_times),\n",
    "                            lowres_cond_img = lowres_cond_img_noisy,\n",
    "                            cond_drop_prob = self.cond_drop_prob'''\n",
    "            \n",
    "        target = noise if pred_objective == 'noise' else x_start\n",
    "        \n",
    "        losses = self.loss_fn(pred, target, reduction = 'none')\n",
    "        losses = reduce(losses, 'b ... -> b', 'mean')\n",
    "\n",
    "        # p2 loss reweighting\n",
    "\n",
    "        if p2_loss_weight_gamma > 0:\n",
    "            loss_weight = (self.p2_loss_weight_k + log_snr.exp()) ** -p2_loss_weight_gamma\n",
    "            losses = losses * loss_weight\n",
    "\n",
    "        return losses.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d97316b9-5e8a-4b36-9561-cb66f86b779a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exists(val):\n",
    "    return val is not None\n",
    "\n",
    "def identity(t, *args, **kwargs):\n",
    "    return t\n",
    "\n",
    "def maybe(fn):\n",
    "    @wraps(fn)\n",
    "    def inner(x):\n",
    "        if not exists(x):\n",
    "            return x\n",
    "        return fn(x)\n",
    "    return inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4d4fe208-acc5-4b99-b5fc-fac579160966",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial, wraps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cd6354f2-f8c8-4c46-a6a8-2e0dbcb8e0e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "def cu(x):\n",
    "    return x + 1\n",
    "\n",
    "p = maybe(cu)(4)\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ceca117e-0e81-46c0-bd48-ace9308e16cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from einops_exts import check_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a9260d5f-5e2f-429f-a59b-f32693cc2f70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[7.6171e-01, 1.0307e-01, 7.5614e-01, 7.5960e-01],\n",
       "          [6.1990e-01, 4.3320e-01, 9.8969e-01, 5.4741e-02],\n",
       "          [3.0489e-01, 6.5976e-01, 7.5253e-01, 3.9645e-01],\n",
       "          [7.5082e-01, 3.0904e-01, 7.9639e-01, 3.8395e-01]],\n",
       "\n",
       "         [[1.4804e-01, 1.4207e-02, 6.3807e-01, 2.8259e-04],\n",
       "          [2.4826e-01, 6.7222e-02, 8.7710e-01, 9.0763e-01],\n",
       "          [9.6059e-02, 8.9632e-01, 3.2495e-01, 3.5925e-01],\n",
       "          [4.1697e-01, 3.3956e-01, 6.8137e-01, 1.4271e-01]],\n",
       "\n",
       "         [[5.1636e-02, 2.3114e-01, 7.9665e-01, 8.4681e-01],\n",
       "          [3.5812e-01, 5.6943e-01, 9.3415e-01, 4.5141e-01],\n",
       "          [8.1132e-01, 3.7259e-01, 6.0285e-01, 9.4935e-01],\n",
       "          [2.7806e-01, 7.9014e-01, 3.4780e-01, 3.0346e-01]]]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand((1,3,4,4))\n",
    "\n",
    "check_shape(x, 'b c h w', c = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "af9154ed-6f60-4bbf-9dea-48b426cb1821",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[7.6171e-01, 1.0307e-01, 7.5614e-01, 7.5960e-01],\n",
       "          [6.1990e-01, 4.3320e-01, 9.8969e-01, 5.4741e-02],\n",
       "          [3.0489e-01, 6.5976e-01, 7.5253e-01, 3.9645e-01],\n",
       "          [7.5082e-01, 3.0904e-01, 7.9639e-01, 3.8395e-01]],\n",
       "\n",
       "         [[1.4804e-01, 1.4207e-02, 6.3807e-01, 2.8259e-04],\n",
       "          [2.4826e-01, 6.7222e-02, 8.7710e-01, 9.0763e-01],\n",
       "          [9.6059e-02, 8.9632e-01, 3.2495e-01, 3.5925e-01],\n",
       "          [4.1697e-01, 3.3956e-01, 6.8137e-01, 1.4271e-01]],\n",
       "\n",
       "         [[5.1636e-02, 2.3114e-01, 7.9665e-01, 8.4681e-01],\n",
       "          [3.5812e-01, 5.6943e-01, 9.3415e-01, 4.5141e-01],\n",
       "          [8.1132e-01, 3.7259e-01, 6.0285e-01, 9.4935e-01],\n",
       "          [2.7806e-01, 7.9014e-01, 3.4780e-01, 3.0346e-01]]]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b78b6f-adea-4acb-b137-92af83f25fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Imagen(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        unets,\n",
    "        *,\n",
    "        image_sizes,                                # for cascading ddpm, image size at each stage\n",
    "        text_encoder_name = 'google/t5-v1_1-small',\n",
    "        text_embed_dim = None,\n",
    "        channels = 3,\n",
    "        timesteps = 1000,\n",
    "        cond_drop_prob = 0.1,\n",
    "        loss_type = 'l2',\n",
    "        noise_schedules = 'cosine',\n",
    "        pred_objectives = 'noise',\n",
    "        lowres_noise_schedule = 'linear',\n",
    "        lowres_sample_noise_level = 0.2,            # in the paper, they present a new trick where they noise the lowres conditioning image, and at sample time, fix it to a certain level (0.1 or 0.3) - the unets are also made to be conditioned on this noise level\n",
    "        per_sample_random_aug_noise_level = False,  # unclear when conditioning on augmentation noise level, whether each batch element receives a random aug noise value - turning off due to @marunine's find\n",
    "        condition_on_text = True,\n",
    "        auto_normalize_img = True,                  # whether to take care of normalizing the image from [0, 1] to [-1, 1] and back automatically - you can turn this off if you want to pass in the [-1, 1] ranged image yourself from the dataloader\n",
    "        continuous_times = True,\n",
    "        p2_loss_weight_gamma = 0.5,                 # p2 loss weight, from https://arxiv.org/abs/2204.00227 - 0 is equivalent to weight of 1 across time\n",
    "        p2_loss_weight_k = 1,\n",
    "        dynamic_thresholding = True,\n",
    "        dynamic_thresholding_percentile = 0.9,      # unsure what this was based on perusal of paper\n",
    "    ):\n",
    "        super(Imagen, self).__init__()\n",
    "        \n",
    "        # loss\n",
    "\n",
    "        self.loss_type   = 'l2'\n",
    "        self.loss_fn     = F.mse_loss\n",
    "        self.channels    = channels\n",
    "        self.image_sizes = image_sizes\n",
    "\n",
    "        # conditioning hparams\n",
    "\n",
    "        self.condition_on_text, self.unconditional = True, False   \n",
    "        \n",
    "        self.lowres_sample_noise_level         = lowres_sample_noise_level\n",
    "        self.per_sample_random_aug_noise_level = per_sample_random_aug_noise_level # False\n",
    "\n",
    "        n_unets   = len(unets)\n",
    "        timesteps = (timesteps,)*n_unets  \n",
    "        \n",
    "        noise_schedules = (noise_schedules, 'cosine')\n",
    "        mults           = n_unets - len(noise_schedules) if n_unets - len(noise_schedules) > 0 else 0\n",
    "        noise_schedules = (*noise_schedules, *('linear',)*mults)\n",
    "\n",
    "        self.lowres_noise_schedule = GaussianDiffusion(noise_type=lowres_noise_schedule)\n",
    "        self.pred_objectives       = (pred_objectives,)*n_unets\n",
    "\n",
    "        self.text_encoder_name = text_encoder_name\n",
    "        self.text_embed_dim    = TextEncoderT5Based(text_encoder_name).embed_dim\n",
    "        self.text_encoder      = TextEncoderT5Based(text_encoder_name)     \n",
    "\n",
    "        self.noise_schedulers = nn.ModuleList([])\n",
    "        for timestep, noise_schedule in zip(timesteps, noise_schedules):\n",
    "            noise_scheduler = GaussianDiffusion(noise_type=noise_schedule, timesteps=timestep)\n",
    "            self.noise_schedulers.append(noise_scheduler)\n",
    "            \n",
    "        self.unets = nn.ModuleList([])        \n",
    "        for i, current_unet in enumerate(unets):\n",
    "            self.unets.append(current_unet.lowres_change(lowres_cond = not (i == 0)))\n",
    "\n",
    "        self.sample_channels = (self.channels,)*n_unets\n",
    "\n",
    "        lowres_conditions = tuple([t.lowres_cond for t in self.unets])\n",
    "        # assert lowres_conditions == (False, *((True,) * (n_unets - 1)))\n",
    "\n",
    "        self.cond_drop_prob          = cond_drop_prob\n",
    "        self.can_classifier_guidance = cond_drop_prob > 0.\n",
    "\n",
    "        self.normalize_img   = normalize_neg_one_to_one  # if auto_normalize_img else identity\n",
    "        self.unnormalize_img = unnormalize_zero_to_one   # if auto_normalize_img else identity\n",
    "\n",
    "\n",
    "        self.dynamic_thresholding            = (dynamic_thresholding,)*n_unets\n",
    "        self.dynamic_thresholding_percentile = dynamic_thresholding_percentile\n",
    "\n",
    "        self.p2_loss_weight_k     = p2_loss_weight_k\n",
    "        self.p2_loss_weight_gamma = (p2_loss_weight_gamma,)*n_unets\n",
    "\n",
    "        self.register_buffer('_temp', torch.tensor([0.]), persistent = False)\n",
    "\n",
    "        self.to(next(self.unets.parameters()).device)\n",
    "        \n",
    "    @property\n",
    "    def device(self):\n",
    "        return self._temp.device\n",
    "\n",
    "    def get_unet(self, unet_number):\n",
    "        assert 0 < unet_number <= len(self.unets)\n",
    "        index = unet_number - 1\n",
    "        return self.unets[index]\n",
    "\n",
    "    @contextmanager\n",
    "    def one_unet_in_gpu(self, unet_number = None, unet = None):\n",
    "        assert exists(unet_number) ^ exists(unet)\n",
    "\n",
    "        if exists(unet_number):\n",
    "            unet = self.get_unet(unet_number)\n",
    "\n",
    "        self.cuda()\n",
    "\n",
    "        devices = [module_device(unet) for unet in self.unets]\n",
    "        self.unets.cpu()\n",
    "        unet.cuda()\n",
    "\n",
    "        yield\n",
    "\n",
    "        for unet, device in zip(self.unets, devices):\n",
    "            unet.to(device)\n",
    "            \n",
    "    def p_losses(self, unet, x_start, times, text_embeds = None, text_mask = None, cond_images = None,\n",
    "             noise_scheduler,\n",
    "             lowres_cond_img = None, lowres_aug_times = None, \n",
    "             ### noise = None, times_next = None,\n",
    "             pred_objective = 'noise', p2_loss_weight_gamma = 0.):\n",
    "        \n",
    "        \n",
    "        noise = noise if noise is not None else torch.randn_like(x_start)\n",
    "        noise = default(noise, lambda: )\n",
    "\n",
    "        # get x_t\n",
    "        x_start          = self.normalize_img(x_start)\n",
    "        x_noisy, log_snr = noise_scheduler.q_sample(x_start = x_start, t = times, noise = noise)\n",
    "        \n",
    "        lowres_cond_img_noisy = None\n",
    "        if lowres_cond_img is not None:      \n",
    "            lowres_cond_img  = self.normalize_img(lowres_cond_img)            \n",
    "            lowres_aug_times = lowres_aug_times if lowres_aug_times is not None else times\n",
    "            \n",
    "            lowres_cond_img_noisy, _ = self.lowres_noise_schedule.q_sample(x_start = lowres_cond_img, t = lowres_aug_times, noise = torch.randn_like(lowres_cond_img))\n",
    "            \n",
    "        pred = unet.forward(x_noisy,\n",
    "                            noise_scheduler.get_condition(times),\n",
    "                            text_embeds = text_embeds,\n",
    "                            text_mask = text_mask)         \n",
    "                            '''cond_images = cond_images,\n",
    "                            lowres_noise_times = self.lowres_noise_schedule.get_condition(lowres_aug_times),\n",
    "                            lowres_cond_img = lowres_cond_img_noisy,\n",
    "                            cond_drop_prob = self.cond_drop_prob'''\n",
    "            \n",
    "        target = noise if pred_objective == 'noise' else x_start\n",
    "        \n",
    "        losses = self.loss_fn(pred, target, reduction = 'none')\n",
    "        losses = reduce(losses, 'b ... -> b', 'mean')\n",
    "\n",
    "        # p2 loss reweighting\n",
    "\n",
    "        if p2_loss_weight_gamma > 0:\n",
    "            loss_weight = (self.p2_loss_weight_k + log_snr.exp()) ** -p2_loss_weight_gamma\n",
    "            losses = losses * loss_weight\n",
    "\n",
    "        return losses.mean()\n",
    "    \n",
    "    def forward(self, images, texts: List[str], unet_number, cond_images = None):  \n",
    "\n",
    "        unet_index = unet_number - 1        \n",
    "        unet       = self.unets[unet_index]\n",
    "\n",
    "        noise_scheduler      = self.noise_schedulers[unet_index]\n",
    "        p2_loss_weight_gamma = self.p2_loss_weight_gamma[unet_index]\n",
    "        pred_objective       = self.pred_objectives[unet_index]\n",
    "        target_image_size    = self.image_sizes[unet_index]\n",
    "        prev_image_size      = self.image_sizes[unet_index - 1] if unet_index > 0 else None\n",
    "        b, c, h, w, device,  = *images.shape, images.device\n",
    "\n",
    "        times = noise_scheduler.sample_random_times(b, device = device)\n",
    "\n",
    "        text_embeds, text_masks = self.text_encoder(texts)\n",
    "        text_embeds = tuple([t.to(images.device) for t in text_embeds])\n",
    "        text_masks  = tuple([t.to(images.device) for t in text_masks])\n",
    "\n",
    "        assert not (text_embeds.shape[-1] != self.text_embed_dim), f'invalid text embedding dimension'\n",
    "\n",
    "        lowres_cond_img = lowres_aug_times = None\n",
    "        if prev_image_size is not None:      \n",
    "            lowres_cond_img = resize_image_to(resize_image_to(images, prev_image_size), target_image_size)\n",
    "            lowres_aug_time = repeat(self.lowres_noise_schedule.sample_random_times(1, device = device), '1 -> b', b = b)\n",
    "\n",
    "\n",
    "        images = resize_image_to(images, target_image_size)\n",
    "        \n",
    "        '''p_losses(self, unet, x_start, times, text_embeds = None, text_mask = None, cond_images = None,\n",
    "                    noise_scheduler,\n",
    "                    lowres_cond_img = None, lowres_aug_times = None, \n",
    "                    ### noise = None, times_next = None,\n",
    "                    pred_objective = 'noise', p2_loss_weight_gamma = 0.)'''\n",
    "\n",
    "        return self.p_losses(unet, images, times, text_embeds=text_embeds, text_mask=text_masks,cond_images=cond_images,\n",
    "                             noise_scheduler = noise_scheduler,\n",
    "                             lowres_cond_img = lowres_cond_img, lowres_aug_times = lowres_aug_times,\n",
    "                             pred_objective = pred_objective, p2_loss_weight_gamma = p2_loss_weight_gamma)\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522de218-009f-4a47-b724-dcd5686b45e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "    @eval_decorator\n",
    "    def sample(self, texts: List[str] = None, cond_images = None, batch_size = 1,cond_scale = 1.,\n",
    "               lowres_sample_noise_level = None, stop_at_unet_number = None, return_all_unet_outputs = False,\n",
    "               return_pil_images = False, device = 'cpu'):\n",
    "\n",
    "        text_embeds, text_masks = self.text_encoder.textEncoder(texts)\n",
    "\n",
    "        # NECESSÁRIO CORREÇÃO\n",
    "\n",
    "        # text_embeds = [t.to(images.device) for t in text_embeds]\n",
    "        # text_masks  = [t.to(images.device) for t in text_masks]\n",
    "        text_embeds, text_masks = map(lambda t: t.to(images.device), (text_embeds, text_masks))\n",
    "            \n",
    "        batch_size = text_embeds.shape[0]\n",
    "\n",
    "        assert not (text_embeds.shape[-1] != self.text_embed_dim)\n",
    "\n",
    "        outputs = []\n",
    "\n",
    "        is_cuda = next(self.parameters()).is_cuda\n",
    "        device  = next(self.parameters()).device\n",
    "\n",
    "        lowres_sample_noise_level = lowres_sample_noise_level if lowres_sample_noise_level is not None else self.lowres_sample_noise_level\n",
    "\n",
    "        for unet_number, unet, channel, image_size, noise_scheduler, pred_objective, dynamic_threshold in tqdm(zip(range(1, len(self.unets) + 1), self.unets, self.sample_channels, self.image_sizes, self.noise_schedulers, self.pred_objectives, self.dynamic_thresholding)):\n",
    "\n",
    "            context = self.one_unet_in_gpu(unet = unet) if is_cuda else null_context()\n",
    "\n",
    "            with context:\n",
    "                lowres_cond_img = lowres_noise_times = None\n",
    "                shape = (batch_size, channel, image_size, image_size)\n",
    "\n",
    "                if unet.lowres_cond:\n",
    "                    lowres_noise_times = self.lowres_noise_schedule.get_times(batch_size, lowres_sample_noise_level, device = device)\n",
    "\n",
    "                    lowres_cond_img = resize_image_to(img, image_size)\n",
    "                    lowres_cond_img, _ = self.lowres_noise_schedule.q_sample(x_start = lowres_cond_img, t = lowres_noise_times, noise = torch.randn_like(lowres_cond_img))\n",
    "\n",
    "                shape = (batch_size, self.channels, image_size, image_size)\n",
    "\n",
    "                img = self.p_sample_loop(unet, shape, text_embeds = text_embeds, text_mask = text_masks, cond_images = cond_images,\n",
    "                                         cond_scale = cond_scale, lowres_cond_img = lowres_cond_img, lowres_noise_times = lowres_noise_times,\n",
    "                                         noise_scheduler = noise_scheduler, pred_objective = pred_objective, dynamic_threshold = dynamic_threshold)\n",
    "\n",
    "                outputs.append(img)\n",
    "\n",
    "            if stop_at_unet_number is not None and stop_at_unet_number == unet_number:\n",
    "                break\n",
    "\n",
    "        output_index = -1 if not return_all_unet_outputs else slice(None) # either return last unet output or all unet outputs\n",
    "\n",
    "        if not return_pil_images:\n",
    "            return outputs[output_index]\n",
    "\n",
    "        if not return_all_unet_outputs:\n",
    "            outputs = outputs[-1:]\n",
    "\n",
    "        pil_images = list(map(lambda img: list(map(T.ToPILImage(), img.unbind(dim = 0))), outputs))\n",
    "\n",
    "        return pil_images[output_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70bc7d36-d643-461d-9f28-615df67a8464",
   "metadata": {},
   "outputs": [],
   "source": [
    "    @torch.no_grad()\n",
    "    def p_sample_loop(self, unet, shape, text_embeds = None, text_mask = None, cond_images = None,\n",
    "                      cond_scale = 1, lowres_cond_img = None, lowres_noise_times = None,\n",
    "                      noise_scheduler, pred_objective = 'noise', dynamic_threshold = True):\n",
    "        \n",
    "        device = self.device\n",
    "        batch  = shape[0]\n",
    "        img    = torch.randn(shape, device = device)\n",
    "        \n",
    "        lowres_cond_img = lowres_cond_img if is None else self.normalize_img(lowres_cond_img)\n",
    "        timesteps       = noise_scheduler.get_sampling_timesteps(batch, device = device)\n",
    "\n",
    "        for times, times_next in tqdm(timesteps, desc = 'sampling loop time step', total = len(timesteps)):\n",
    "            \n",
    "            img = self.p_sample(unet, img, times, t_next = times_next, text_embeds = text_embeds, text_mask = text_mask,\n",
    "                                cond_images = cond_images, cond_scale = cond_scale, lowres_cond_img = lowres_cond_img,\n",
    "                                lowres_noise_times = lowres_noise_times, noise_scheduler = noise_scheduler, \n",
    "                                pred_objective = pred_objective, dynamic_threshold = dynamic_threshold)\n",
    "\n",
    "        img.clamp_(-1., 1.)\n",
    "        unnormalize_img = self.unnormalize_img(img)\n",
    "        return unnormalize_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a127fb54-6057-44e8-9a57-dc561f633ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "    @torch.no_grad()\n",
    "    def p_sample(self, unet, x, t, t_next = None, text_embeds = None, text_mask = None,\n",
    "                 cond_images = None, cond_scale = 1., lowres_cond_img = None,\n",
    "                 lowres_noise_times = None, noise_scheduler = None,\n",
    "                 pred_objective = 'noise', dynamic_threshold = True):\n",
    "        \n",
    "        # b, *_, device = *x.shape, x.device\n",
    "        b, device = *x.shape[0], x.device\n",
    "        \n",
    "        model_mean, _, model_log_variance = self.p_mean_variance(unet, x = x, t = t, t_next = t_next, text_embeds = text_embeds, text_mask = text_mask,\n",
    "                                                                 cond_images = cond_images, cond_scale = cond_scale, lowres_cond_img = lowres_cond_img,\n",
    "                                                                 lowres_noise_times = lowres_noise_times, noise_scheduler = noise_scheduler,\n",
    "                                                                 pred_objective = pred_objective, dynamic_threshold = dynamic_threshold)\n",
    "        \n",
    "        noise = torch.randn_like(x)\n",
    "\n",
    "        is_last_sampling_timestep = (t_next == 0) if isinstance(noise_scheduler, GaussianDiffusionContinuousTimes) else (t == 0)\n",
    "        nonzero_mask = (1 - is_last_sampling_timestep.float()).reshape(b, *((1,) * (len(x.shape) - 1)))\n",
    "        \n",
    "        return model_mean + nonzero_mask * (0.5 * model_log_variance).exp() * noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37cb712c-a936-49bb-bcf2-251eb7f2142e",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def p_mean_variance(self, unet, x, t, t_next = None, text_embeds = None, text_mask = None,\n",
    "                        cond_images = None, cond_scale = 1., lowres_cond_img = None,\n",
    "                        lowres_noise_times = None, noise_scheduler,  \n",
    "                        pred_objective = 'noise', dynamic_threshold = True, model_output = None):\n",
    "        \n",
    "        assert not (cond_scale != 1. and not self.can_classifier_guidance), 'imagen was not trained with conditional dropout, and thus one cannot use classifier free guidance (cond_scale anything other than 1)'\n",
    "\n",
    "        pred = default(model_output, lambda: unet.forward_with_cond_scale(x, noise_scheduler.get_condition(t), text_embeds = text_embeds, text_mask = text_mask, cond_images = cond_images, cond_scale = cond_scale, lowres_cond_img = lowres_cond_img, lowres_noise_times = self.lowres_noise_schedule.get_condition(lowres_noise_times)))\n",
    "\n",
    "        x_start = noise_scheduler.predict_start_from_noise(x, t = t, noise = pred) if pred_objective == 'noise' else pred\n",
    "\n",
    "        if dynamic_threshold:\n",
    "            # following pseudocode in appendix\n",
    "            # s is the dynamic threshold, determined by percentile of absolute values of reconstructed sample per batch element\n",
    "            s = torch.quantile(rearrange(x_start, 'b ... -> b (...)').abs(),\n",
    "                               self.dynamic_thresholding_percentile,\n",
    "                               dim = -1)\n",
    "\n",
    "            s.clamp_(min = 1.)\n",
    "            s = right_pad_dims_to(x_start, s)\n",
    "            x_start = x_start.clamp(-s, s) / s\n",
    "        else:\n",
    "            x_start.clamp_(-1., 1.)\n",
    "\n",
    "        return noise_scheduler.q_posterior(x_start = x_start, x_t = x, t = t, t_next = t_next)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f83370-47bd-4bfa-868b-4e8f8413b51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_with_cond_scale(self, *args, cond_scale = 1., **kwargs):\n",
    "    \n",
    "        logits = self.forward(*args, **kwargs)\n",
    "        if cond_scale == 1:\n",
    "            return logits\n",
    "        null_logits = self.forward(*args, cond_drop_prob = 1., **kwargs)\n",
    "        return null_logits + (logits - null_logits) * cond_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6891ec-7f5a-49e3-8386-7dc768437a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def p_mean_variance(self, unet, x, t, t_next = None, text_embeds = None, text_mask = None,\n",
    "                        cond_images = None, cond_scale = 1., lowres_cond_img = None,\n",
    "                        lowres_noise_times = None, noise_scheduler,  \n",
    "                        pred_objective = 'noise', dynamic_threshold = True, model_output = None):\n",
    "        \n",
    "        assert not (cond_scale != 1. and not self.can_classifier_guidance), 'imagen was not trained with conditional dropout, and thus one cannot use classifier free guidance (cond_scale anything other than 1)'\n",
    "\n",
    "        pred = default(model_output, lambda: unet.forward_with_cond_scale(x, noise_scheduler.get_condition(t), text_embeds = text_embeds, text_mask = text_mask, cond_images = cond_images, cond_scale = cond_scale, lowres_cond_img = lowres_cond_img, lowres_noise_times = self.lowres_noise_schedule.get_condition(lowres_noise_times)))\n",
    "\n",
    "        x_start = noise_scheduler.predict_start_from_noise(x, t = t, noise = pred) if pred_objective == 'noise' else pred\n",
    "\n",
    "        if dynamic_threshold:\n",
    "            # following pseudocode in appendix\n",
    "            # s is the dynamic threshold, determined by percentile of absolute values of reconstructed sample per batch element\n",
    "            s = torch.quantile(rearrange(x_start, 'b ... -> b (...)').abs(),\n",
    "                               self.dynamic_thresholding_percentile,\n",
    "                               dim = -1)\n",
    "\n",
    "            s.clamp_(min = 1.)\n",
    "            s = right_pad_dims_to(x_start, s)\n",
    "            x_start = x_start.clamp(-s, s) / s\n",
    "        else:\n",
    "            x_start.clamp_(-1., 1.)\n",
    "\n",
    "        return noise_scheduler.q_posterior(x_start = x_start, x_t = x, t = t, t_next = t_next)\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def p_sample(self, unet, x, t, t_next = None, text_embeds = None, text_mask = None,\n",
    "                 cond_images = None, cond_scale = 1., lowres_cond_img = None,\n",
    "                 lowres_noise_times = None, noise_scheduler = None,\n",
    "                 pred_objective = 'noise', dynamic_threshold = True):\n",
    "        \n",
    "        # b, *_, device = *x.shape, x.device\n",
    "        b, device = *x.shape[0], x.device\n",
    "        \n",
    "        model_mean, _, model_log_variance = self.p_mean_variance(unet, x = x, t = t, t_next = t_next, text_embeds = text_embeds, text_mask = text_mask,\n",
    "                                                                 cond_images = cond_images, cond_scale = cond_scale, lowres_cond_img = lowres_cond_img,\n",
    "                                                                 lowres_noise_times = lowres_noise_times, noise_scheduler = noise_scheduler,\n",
    "                                                                 pred_objective = pred_objective, dynamic_threshold = dynamic_threshold)\n",
    "        \n",
    "        noise = torch.randn_like(x)\n",
    "\n",
    "        is_last_sampling_timestep = (t_next == 0) if isinstance(noise_scheduler, GaussianDiffusionContinuousTimes) else (t == 0)\n",
    "        nonzero_mask = (1 - is_last_sampling_timestep.float()).reshape(b, *((1,) * (len(x.shape) - 1)))\n",
    "        \n",
    "        return model_mean + nonzero_mask * (0.5 * model_log_variance).exp() * noise\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def p_sample_loop(self, unet, shape, text_embeds = None, text_mask = None, cond_images = None,\n",
    "                      cond_scale = 1, lowres_cond_img = None, lowres_noise_times = None,\n",
    "                      noise_scheduler, pred_objective = 'noise', dynamic_threshold = True):\n",
    "        \n",
    "        device = self.device\n",
    "        batch  = shape[0]\n",
    "        img    = torch.randn(shape, device = device)\n",
    "        \n",
    "        lowres_cond_img = lowres_cond_img if is None else self.normalize_img(lowres_cond_img)\n",
    "        timesteps       = noise_scheduler.get_sampling_timesteps(batch, device = device)\n",
    "\n",
    "        for times, times_next in tqdm(timesteps, desc = 'sampling loop time step', total = len(timesteps)):\n",
    "            \n",
    "            img = self.p_sample(unet, img, times, t_next = times_next, text_embeds = text_embeds, text_mask = text_mask,\n",
    "                                cond_images = cond_images, cond_scale = cond_scale, lowres_cond_img = lowres_cond_img,\n",
    "                                lowres_noise_times = lowres_noise_times, noise_scheduler = noise_scheduler, \n",
    "                                pred_objective = pred_objective, dynamic_threshold = dynamic_threshold)\n",
    "\n",
    "        img.clamp_(-1., 1.)\n",
    "        unnormalize_img = self.unnormalize_img(img)\n",
    "        return unnormalize_img\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    @eval_decorator\n",
    "    def sample(self, texts: List[str] = None, cond_images = None, batch_size = 1,cond_scale = 1.,\n",
    "               lowres_sample_noise_level = None, stop_at_unet_number = None, return_all_unet_outputs = False,\n",
    "               return_pil_images = False, device = 'cpu'):\n",
    "\n",
    "        text_embeds, text_masks = self.text_encoder.textEncoder(texts)\n",
    "\n",
    "        # NECESSÁRIO CORREÇÃO\n",
    "\n",
    "        # text_embeds = [t.to(images.device) for t in text_embeds]\n",
    "        # text_masks  = [t.to(images.device) for t in text_masks]\n",
    "        text_embeds, text_masks = map(lambda t: t.to(images.device), (text_embeds, text_masks))\n",
    "            \n",
    "        batch_size = text_embeds.shape[0]\n",
    "\n",
    "        assert not (text_embeds.shape[-1] != self.text_embed_dim)\n",
    "\n",
    "        outputs = []\n",
    "\n",
    "        is_cuda = next(self.parameters()).is_cuda\n",
    "        device  = next(self.parameters()).device\n",
    "\n",
    "        lowres_sample_noise_level = lowres_sample_noise_level if lowres_sample_noise_level is not None else self.lowres_sample_noise_level\n",
    "\n",
    "        for unet_number, unet, channel, image_size, noise_scheduler, pred_objective, dynamic_threshold in tqdm(zip(range(1, len(self.unets) + 1), self.unets, self.sample_channels, self.image_sizes, self.noise_schedulers, self.pred_objectives, self.dynamic_thresholding)):\n",
    "\n",
    "            context = self.one_unet_in_gpu(unet = unet) if is_cuda else null_context()\n",
    "\n",
    "            with context:\n",
    "                lowres_cond_img = lowres_noise_times = None\n",
    "                shape = (batch_size, channel, image_size, image_size)\n",
    "\n",
    "                if unet.lowres_cond:\n",
    "                    lowres_noise_times = self.lowres_noise_schedule.get_times(batch_size, lowres_sample_noise_level, device = device)\n",
    "\n",
    "                    lowres_cond_img = resize_image_to(img, image_size)\n",
    "                    lowres_cond_img, _ = self.lowres_noise_schedule.q_sample(x_start = lowres_cond_img, t = lowres_noise_times, noise = torch.randn_like(lowres_cond_img))\n",
    "\n",
    "                shape = (batch_size, self.channels, image_size, image_size)\n",
    "\n",
    "                img = self.p_sample_loop(unet, shape, text_embeds = text_embeds, text_mask = text_masks, cond_images = cond_images,\n",
    "                                         cond_scale = cond_scale, lowres_cond_img = lowres_cond_img, lowres_noise_times = lowres_noise_times,\n",
    "                                         noise_scheduler = noise_scheduler, pred_objective = pred_objective, dynamic_threshold = dynamic_threshold)\n",
    "\n",
    "                outputs.append(img)\n",
    "\n",
    "            if stop_at_unet_number is not None and stop_at_unet_number == unet_number:\n",
    "                break\n",
    "\n",
    "        output_index = -1 if not return_all_unet_outputs else slice(None) # either return last unet output or all unet outputs\n",
    "\n",
    "        if not return_pil_images:\n",
    "            return outputs[output_index]\n",
    "\n",
    "        if not return_all_unet_outputs:\n",
    "            outputs = outputs[-1:]\n",
    "\n",
    "        pil_images = list(map(lambda img: list(map(T.ToPILImage(), img.unbind(dim = 0))), outputs))\n",
    "\n",
    "        return pil_images[output_index]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
