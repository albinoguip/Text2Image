{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3e572d0-98b1-4e0f-ae3e-f8d0fe3faad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers\n",
    "from transformers import T5Tokenizer, T5EncoderModel, T5Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51fce889-f429-4936-9bfa-3cbdc7deb153",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config\n",
    "\n",
    "MAX_LENGTH = 256\n",
    "\n",
    "DEFAULT_T5_NAME = 'google/t5-v1_1-base'\n",
    "\n",
    "T5_CONFIGS = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a668a29c-12d4-478c-ae3e-85e48c0e3c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# singleton globals\n",
    "\n",
    "def get_tokenizer(name):\n",
    "    tokenizer = T5Tokenizer.from_pretrained(name)\n",
    "    return tokenizer\n",
    "\n",
    "def get_model(name):\n",
    "    model = T5EncoderModel.from_pretrained(name)\n",
    "    return model\n",
    "\n",
    "def get_model_and_tokenizer(name):\n",
    "    global T5_CONFIGS\n",
    "\n",
    "    if name not in T5_CONFIGS:\n",
    "        T5_CONFIGS[name] = dict()\n",
    "    if \"model\" not in T5_CONFIGS[name]:\n",
    "        T5_CONFIGS[name][\"model\"] = get_model(name)\n",
    "    if \"tokenizer\" not in T5_CONFIGS[name]:\n",
    "        T5_CONFIGS[name][\"tokenizer\"] = get_tokenizer(name)\n",
    "\n",
    "    return T5_CONFIGS[name]['model'], T5_CONFIGS[name]['tokenizer']\n",
    "\n",
    "def get_encoded_dim(name):\n",
    "    if name not in T5_CONFIGS:\n",
    "        # avoids loading the model if we only want to get the dim\n",
    "        config = T5Config.from_pretrained(name)\n",
    "        T5_CONFIGS[name] = dict(config=config)\n",
    "    elif \"config\" in T5_CONFIGS[name]:\n",
    "        config = T5_CONFIGS[name][\"config\"]\n",
    "    elif \"model\" in T5_CONFIGS[name]:\n",
    "        config = T5_CONFIGS[name][\"model\"].config\n",
    "    else:\n",
    "        assert False\n",
    "    return config.d_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "93acfbd5-d4b3-4a7b-bed6-2a15f633eab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding text\n",
    "\n",
    "def t5_encode_text(texts, name = DEFAULT_T5_NAME):\n",
    "    t5, tokenizer = get_model_and_tokenizer(name)\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        t5 = t5.cuda()\n",
    "\n",
    "    device = next(t5.parameters()).device\n",
    "    print(device)\n",
    "\n",
    "    encoded = tokenizer.batch_encode_plus(\n",
    "        texts,\n",
    "        return_tensors = \"pt\",\n",
    "        padding = 'longest',\n",
    "        max_length = MAX_LENGTH,\n",
    "        truncation = True\n",
    "    )\n",
    "\n",
    "    input_ids = encoded.input_ids.to(device)\n",
    "    attn_mask = encoded.attention_mask.to(device)\n",
    "\n",
    "    t5.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = t5(input_ids = input_ids, attention_mask = attn_mask)\n",
    "        encoded_text = output.last_hidden_state.detach()\n",
    "\n",
    "    return encoded_text, attn_mask.bool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c4b35faa-3b11-4f0f-bce2-b096137148d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextEncoderT5Based():\n",
    "    \n",
    "    def __init__(self, name = 'google/t5-v1_1-small', device='cpu'):\n",
    "        \n",
    "        self.device    = device\n",
    "        self.model     = T5EncoderModel.from_pretrained(name).to(device)\n",
    "        self.tokenizer = T5Tokenizer.from_pretrained(name)\n",
    "        \n",
    "    def textEncoder(self, texts):\n",
    "        \n",
    "        text_encoded = self.tokenizer.batch_encode_plus(texts,return_tensors = \"pt\", padding = 'longest',\n",
    "                                                        max_length = MAX_LENGTH, truncation = True)\n",
    "        \n",
    "        text_ids = text_encoded.input_ids.to(self.device)\n",
    "        mask     = text_encoded.attention_mask.to(self.device)\n",
    "        \n",
    "        self.model.eval()\n",
    "        \n",
    "        with torch.no_grad(): encoded_text = self.model(text_ids, mask).last_hidden_state.detach()\n",
    "                \n",
    "        return encoded_text, mask.bool()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dacb2641-9b65-4c20-b494-6921fbce43ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/t5-v1_1-small were not used when initializing T5EncoderModel: ['decoder.embed_tokens.weight', 'decoder.block.0.layer.0.SelfAttention.q.weight', 'decoder.block.0.layer.0.SelfAttention.k.weight', 'decoder.block.0.layer.0.SelfAttention.v.weight', 'decoder.block.0.layer.0.SelfAttention.o.weight', 'decoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight', 'decoder.block.0.layer.0.layer_norm.weight', 'decoder.block.0.layer.1.EncDecAttention.q.weight', 'decoder.block.0.layer.1.EncDecAttention.k.weight', 'decoder.block.0.layer.1.EncDecAttention.v.weight', 'decoder.block.0.layer.1.EncDecAttention.o.weight', 'decoder.block.0.layer.1.layer_norm.weight', 'decoder.block.0.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.0.layer.2.DenseReluDense.wi_1.weight', 'decoder.block.0.layer.2.DenseReluDense.wo.weight', 'decoder.block.0.layer.2.layer_norm.weight', 'decoder.block.1.layer.0.SelfAttention.q.weight', 'decoder.block.1.layer.0.SelfAttention.k.weight', 'decoder.block.1.layer.0.SelfAttention.v.weight', 'decoder.block.1.layer.0.SelfAttention.o.weight', 'decoder.block.1.layer.0.layer_norm.weight', 'decoder.block.1.layer.1.EncDecAttention.q.weight', 'decoder.block.1.layer.1.EncDecAttention.k.weight', 'decoder.block.1.layer.1.EncDecAttention.v.weight', 'decoder.block.1.layer.1.EncDecAttention.o.weight', 'decoder.block.1.layer.1.layer_norm.weight', 'decoder.block.1.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.1.layer.2.DenseReluDense.wi_1.weight', 'decoder.block.1.layer.2.DenseReluDense.wo.weight', 'decoder.block.1.layer.2.layer_norm.weight', 'decoder.block.2.layer.0.SelfAttention.q.weight', 'decoder.block.2.layer.0.SelfAttention.k.weight', 'decoder.block.2.layer.0.SelfAttention.v.weight', 'decoder.block.2.layer.0.SelfAttention.o.weight', 'decoder.block.2.layer.0.layer_norm.weight', 'decoder.block.2.layer.1.EncDecAttention.q.weight', 'decoder.block.2.layer.1.EncDecAttention.k.weight', 'decoder.block.2.layer.1.EncDecAttention.v.weight', 'decoder.block.2.layer.1.EncDecAttention.o.weight', 'decoder.block.2.layer.1.layer_norm.weight', 'decoder.block.2.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.2.layer.2.DenseReluDense.wi_1.weight', 'decoder.block.2.layer.2.DenseReluDense.wo.weight', 'decoder.block.2.layer.2.layer_norm.weight', 'decoder.block.3.layer.0.SelfAttention.q.weight', 'decoder.block.3.layer.0.SelfAttention.k.weight', 'decoder.block.3.layer.0.SelfAttention.v.weight', 'decoder.block.3.layer.0.SelfAttention.o.weight', 'decoder.block.3.layer.0.layer_norm.weight', 'decoder.block.3.layer.1.EncDecAttention.q.weight', 'decoder.block.3.layer.1.EncDecAttention.k.weight', 'decoder.block.3.layer.1.EncDecAttention.v.weight', 'decoder.block.3.layer.1.EncDecAttention.o.weight', 'decoder.block.3.layer.1.layer_norm.weight', 'decoder.block.3.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.3.layer.2.DenseReluDense.wi_1.weight', 'decoder.block.3.layer.2.DenseReluDense.wo.weight', 'decoder.block.3.layer.2.layer_norm.weight', 'decoder.block.4.layer.0.SelfAttention.q.weight', 'decoder.block.4.layer.0.SelfAttention.k.weight', 'decoder.block.4.layer.0.SelfAttention.v.weight', 'decoder.block.4.layer.0.SelfAttention.o.weight', 'decoder.block.4.layer.0.layer_norm.weight', 'decoder.block.4.layer.1.EncDecAttention.q.weight', 'decoder.block.4.layer.1.EncDecAttention.k.weight', 'decoder.block.4.layer.1.EncDecAttention.v.weight', 'decoder.block.4.layer.1.EncDecAttention.o.weight', 'decoder.block.4.layer.1.layer_norm.weight', 'decoder.block.4.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.4.layer.2.DenseReluDense.wi_1.weight', 'decoder.block.4.layer.2.DenseReluDense.wo.weight', 'decoder.block.4.layer.2.layer_norm.weight', 'decoder.block.5.layer.0.SelfAttention.q.weight', 'decoder.block.5.layer.0.SelfAttention.k.weight', 'decoder.block.5.layer.0.SelfAttention.v.weight', 'decoder.block.5.layer.0.SelfAttention.o.weight', 'decoder.block.5.layer.0.layer_norm.weight', 'decoder.block.5.layer.1.EncDecAttention.q.weight', 'decoder.block.5.layer.1.EncDecAttention.k.weight', 'decoder.block.5.layer.1.EncDecAttention.v.weight', 'decoder.block.5.layer.1.EncDecAttention.o.weight', 'decoder.block.5.layer.1.layer_norm.weight', 'decoder.block.5.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.5.layer.2.DenseReluDense.wi_1.weight', 'decoder.block.5.layer.2.DenseReluDense.wo.weight', 'decoder.block.5.layer.2.layer_norm.weight', 'decoder.block.6.layer.0.SelfAttention.q.weight', 'decoder.block.6.layer.0.SelfAttention.k.weight', 'decoder.block.6.layer.0.SelfAttention.v.weight', 'decoder.block.6.layer.0.SelfAttention.o.weight', 'decoder.block.6.layer.0.layer_norm.weight', 'decoder.block.6.layer.1.EncDecAttention.q.weight', 'decoder.block.6.layer.1.EncDecAttention.k.weight', 'decoder.block.6.layer.1.EncDecAttention.v.weight', 'decoder.block.6.layer.1.EncDecAttention.o.weight', 'decoder.block.6.layer.1.layer_norm.weight', 'decoder.block.6.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.6.layer.2.DenseReluDense.wi_1.weight', 'decoder.block.6.layer.2.DenseReluDense.wo.weight', 'decoder.block.6.layer.2.layer_norm.weight', 'decoder.block.7.layer.0.SelfAttention.q.weight', 'decoder.block.7.layer.0.SelfAttention.k.weight', 'decoder.block.7.layer.0.SelfAttention.v.weight', 'decoder.block.7.layer.0.SelfAttention.o.weight', 'decoder.block.7.layer.0.layer_norm.weight', 'decoder.block.7.layer.1.EncDecAttention.q.weight', 'decoder.block.7.layer.1.EncDecAttention.k.weight', 'decoder.block.7.layer.1.EncDecAttention.v.weight', 'decoder.block.7.layer.1.EncDecAttention.o.weight', 'decoder.block.7.layer.1.layer_norm.weight', 'decoder.block.7.layer.2.DenseReluDense.wi_0.weight', 'decoder.block.7.layer.2.DenseReluDense.wi_1.weight', 'decoder.block.7.layer.2.DenseReluDense.wo.weight', 'decoder.block.7.layer.2.layer_norm.weight', 'decoder.final_layer_norm.weight', 'lm_head.weight']\n",
      "- This IS expected if you are initializing T5EncoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing T5EncoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "T5 = TextEncoderT5Based()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "74b78256-67a3-43e2-9111-6b83816ae765",
   "metadata": {},
   "outputs": [],
   "source": [
    "t5 = T5.textEncoder(['I', 'you', 'yes my'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e9a9ffb7-5c86-4984-9f91-486ace5eac7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 7.7179e-02, -9.5068e-03,  4.9421e-04,  ..., -1.7528e-01,\n",
       "           -2.7930e-03,  7.0717e-01],\n",
       "          [-3.6950e-01,  8.6838e-02, -1.3701e-01,  ..., -3.6052e-01,\n",
       "           -1.9034e-01,  8.7760e-02],\n",
       "          [ 8.3804e-02, -2.0349e-02,  5.8009e-03,  ..., -1.3579e-01,\n",
       "           -1.9433e-02,  5.5632e-01]],\n",
       " \n",
       "         [[ 7.4668e-02, -2.6701e-02, -3.7860e-03,  ..., -1.2131e-01,\n",
       "           -2.6960e-02,  5.9868e-01],\n",
       "          [-3.0119e-01, -4.8806e-01,  2.6033e-01,  ...,  1.0381e-01,\n",
       "           -7.0362e-01,  9.3447e-01],\n",
       "          [ 2.4214e-03, -1.6723e-01,  1.2286e-01,  ..., -3.0876e-01,\n",
       "           -6.1628e-01,  6.4991e-01]],\n",
       " \n",
       "         [[ 8.1621e-02, -2.6020e-02, -4.7646e-03,  ..., -1.2855e-01,\n",
       "           -2.7603e-02,  6.2340e-01],\n",
       "          [ 4.4333e-01,  2.6897e-01, -2.7354e-01,  ..., -3.6821e-01,\n",
       "           -9.6742e-02, -1.9053e-01],\n",
       "          [-1.2980e-01, -4.0838e-01,  1.0294e-01,  ..., -1.4140e-01,\n",
       "           -4.8038e-01, -3.9026e-01]]]),\n",
       " tensor([[ True,  True, False],\n",
       "         [ True,  True, False],\n",
       "         [ True,  True,  True]]))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "58b08fa3-5023-4955-99de-1f103ff3edfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 7.7179e-02, -9.5068e-03,  4.9421e-04,  ..., -1.7528e-01,\n",
       "           -2.7930e-03,  7.0717e-01],\n",
       "          [-3.6950e-01,  8.6838e-02, -1.3701e-01,  ..., -3.6052e-01,\n",
       "           -1.9034e-01,  8.7760e-02],\n",
       "          [ 8.3804e-02, -2.0349e-02,  5.8009e-03,  ..., -1.3579e-01,\n",
       "           -1.9433e-02,  5.5632e-01]],\n",
       " \n",
       "         [[ 7.4668e-02, -2.6701e-02, -3.7860e-03,  ..., -1.2131e-01,\n",
       "           -2.6960e-02,  5.9868e-01],\n",
       "          [-3.0119e-01, -4.8806e-01,  2.6033e-01,  ...,  1.0381e-01,\n",
       "           -7.0362e-01,  9.3447e-01],\n",
       "          [ 2.4214e-03, -1.6723e-01,  1.2286e-01,  ..., -3.0876e-01,\n",
       "           -6.1628e-01,  6.4991e-01]],\n",
       " \n",
       "         [[ 8.1621e-02, -2.6020e-02, -4.7646e-03,  ..., -1.2855e-01,\n",
       "           -2.7603e-02,  6.2340e-01],\n",
       "          [ 4.4333e-01,  2.6897e-01, -2.7354e-01,  ..., -3.6821e-01,\n",
       "           -9.6742e-02, -1.9053e-01],\n",
       "          [-1.2980e-01, -4.0838e-01,  1.0294e-01,  ..., -1.4140e-01,\n",
       "           -4.8038e-01, -3.9026e-01]]]),\n",
       " tensor([[ True,  True, False],\n",
       "         [ True,  True, False],\n",
       "         [ True,  True,  True]]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = t5_encode_text(['I', 'you', 'yes my'], name = 'google/t5-v1_1-small')\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "efefc43c-fce9-4400-9a43-3c0c27980ea1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 512])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e41c5a2-8d14-46b5-9942-a5cb150fe16e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
