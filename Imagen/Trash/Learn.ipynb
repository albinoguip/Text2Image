{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ede4ab4c-ef68-4429-b7be-0cf64346aa36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f9e1c5bf-0da7-4c38-9479-8635e559b85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exists(val):\n",
    "    return val is not None\n",
    "\n",
    "def default(val, d):\n",
    "    if exists(val):\n",
    "        print('pao')\n",
    "        return val\n",
    "    return d() if callable(d) else d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a42a641c-8152-4858-a671-9c219a84bdb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossEmbedLayer(nn.Module):\n",
    "    def __init__(self, dim_in, kernel_sizes, dim_out = None, stride = 2):\n",
    "        super().__init__()\n",
    "        assert all([*map(lambda t: (t % 2) == (stride % 2), kernel_sizes)])\n",
    "        dim_out = default(dim_out, dim_in)\n",
    "\n",
    "        kernel_sizes = sorted(kernel_sizes)\n",
    "        num_scales = len(kernel_sizes)\n",
    "\n",
    "        # calculate the dimension at each scale\n",
    "        dim_scales = [int(dim_out / (2 ** i)) for i in range(1, num_scales)]\n",
    "        dim_scales = [*dim_scales, dim_out - sum(dim_scales)]\n",
    "\n",
    "        self.convs = nn.ModuleList([])\n",
    "        for kernel, dim_scale in zip(kernel_sizes, dim_scales):\n",
    "            self.convs.append(nn.Conv2d(dim_in, dim_scale, kernel, stride = stride, padding = (kernel - stride) // 2))\n",
    "\n",
    "    def forward(self, x):\n",
    "        fmaps = tuple(map(lambda conv: conv(x), self.convs))\n",
    "        return torch.cat(fmaps, dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7100d29f-289d-483b-bae3-de38e12969ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CrossEmbedLayer(\n",
       "  (convs): ModuleList(\n",
       "    (0): Conv2d(30, 15, kernel_size=(6, 6), stride=(2, 2), padding=(2, 2))\n",
       "    (1): Conv2d(30, 7, kernel_size=(8, 8), stride=(2, 2), padding=(3, 3))\n",
       "    (2): Conv2d(30, 8, kernel_size=(10, 10), stride=(2, 2), padding=(4, 4))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CrossEmbedLayer(dim_in=30, kernel_sizes=[8, 6, 10], dim_out = None, stride = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3c3117da-1559-469b-ac89-5445cc40afd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pao\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CrossEmbedLayer(\n",
       "  (convs): ModuleList(\n",
       "    (0): Conv2d(3, 2, kernel_size=(6, 6), stride=(4, 4), padding=(1, 1))\n",
       "    (1): Conv2d(3, 1, kernel_size=(8, 8), stride=(4, 4), padding=(2, 2))\n",
       "    (2): Conv2d(3, 2, kernel_size=(10, 10), stride=(4, 4), padding=(3, 3))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cel = CrossEmbedLayer(dim_in=3, kernel_sizes=[6, 8, 10], dim_out = 5, stride = 4)\n",
    "cel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "abd967c6-0b2e-47db-89ec-b38521dc0430",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 62, 62])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand((1, 3, 250, 250))\n",
    "y = cel(x)\n",
    "\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "82d5ffb5-054b-4588-8855-7e44905cf9ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = [10, 20]\n",
    "callable(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fb3687-614c-4925-9410-751628bec68d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8adc57-ff68-494a-9cf1-c3b4daf4a3e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8039a1a5-1f7b-4152-a7b9-bd019970d059",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9733e26-b9a7-4935-870e-dab3fba7a614",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff19ce9c-c944-4549-8609-c8f2d024ebd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3e6460-672c-46aa-9ebd-8a3cd0a34953",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Unet(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        *,\n",
    "        dim,\n",
    "        image_embed_dim = 1024,\n",
    "        text_embed_dim = get_encoded_dim(DEFAULT_T5_NAME),\n",
    "        num_resnet_blocks = 1,\n",
    "        cond_dim = None,\n",
    "        num_image_tokens = 4,\n",
    "        num_time_tokens = 2,\n",
    "        learned_sinu_pos_emb = True,\n",
    "        learned_sinu_pos_emb_dim = 16,\n",
    "        out_dim = None,\n",
    "        dim_mults=(1, 2, 4, 8),\n",
    "        cond_images_channels = 0,\n",
    "        channels = 3,\n",
    "        channels_out = None,\n",
    "        attn_dim_head = 64,\n",
    "        attn_heads = 8,\n",
    "        ff_mult = 2.,\n",
    "        lowres_cond = False, # for cascading diffusion - https://cascaded-diffusion.github.io/\n",
    "        layer_attns = True,\n",
    "        attend_at_middle = True, # whether to have a layer of attention at the bottleneck (can turn off for higher resolution in cascading DDPM, before bringing in efficient attention)\n",
    "        layer_cross_attns = True,\n",
    "        use_linear_attn = False,\n",
    "        use_linear_cross_attn = False,\n",
    "        cond_on_text = True,\n",
    "        max_text_len = 256,\n",
    "        init_dim = None,\n",
    "        init_conv_kernel_size = 7,\n",
    "        resnet_groups = 8,\n",
    "        init_cross_embed_kernel_sizes = (3, 7, 15),\n",
    "        cross_embed_downsample = False,\n",
    "        cross_embed_downsample_kernel_sizes = (2, 4),\n",
    "        attn_pool_text = True,\n",
    "        attn_pool_num_latents = 32,\n",
    "        dropout = 0.,\n",
    "        memory_efficient = False,\n",
    "        init_conv_to_final_conv_residual = False,\n",
    "        use_global_context_attn = True,\n",
    "        scale_skip_connection = True,\n",
    "        final_resnet_block = True,\n",
    "        final_conv_kernel_size = 3,\n",
    "        bilinear_upsample = False,                   # for debugging checkboard artifacts\n",
    "        antialias_downsample = False,                # for debugging checkboard artifacts\n",
    "        downsample_concat_hiddens_earlier = False    # for debugging artifacts in memory efficient unet (allows for one to concat the hiddens a bit earlier, right after the downsample)\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        # guide researchers\n",
    "\n",
    "        assert attn_heads > 1, 'you need to have more than 1 attention head, ideally at least 4 or 8'\n",
    "\n",
    "        if dim < 128:\n",
    "            print('The base dimension of your u-net should ideally be no smaller than 128, as recommended by a professional DDPM trainer https://nonint.com/2022/05/04/friends-dont-let-friends-train-small-diffusion-models/')\n",
    "\n",
    "        # save locals to take care of some hyperparameters for cascading DDPM\n",
    "\n",
    "        self._locals = locals()\n",
    "        self._locals.pop('self', None)\n",
    "        self._locals.pop('__class__', None)\n",
    "\n",
    "        # for eventual cascading diffusion\n",
    "\n",
    "        self.lowres_cond = lowres_cond\n",
    "\n",
    "\n",
    "        # determine dimensions\n",
    "\n",
    "        self.channels = channels\n",
    "        self.channels_out = default(channels_out, channels)\n",
    "\n",
    "        init_channels = channels if not lowres_cond else channels * 2 # in cascading diffusion, one concats the low resolution image, blurred, for conditioning the higher resolution synthesis\n",
    "        init_dim = default(init_dim, dim)\n",
    "\n",
    "        # optional image conditioning\n",
    "\n",
    "        self.has_cond_image = cond_images_channels > 0\n",
    "        self.cond_images_channels = cond_images_channels\n",
    "\n",
    "        init_channels += cond_images_channels\n",
    "\n",
    "        # initial convolution\n",
    "\n",
    "        self.init_conv = CrossEmbedLayer(init_channels, dim_out = init_dim, kernel_sizes = init_cross_embed_kernel_sizes, stride = 1)\n",
    "\n",
    "        dims = [init_dim, *map(lambda m: dim * m, dim_mults)]\n",
    "        in_out = list(zip(dims[:-1], dims[1:]))\n",
    "\n",
    "        # time conditioning\n",
    "\n",
    "        cond_dim = default(cond_dim, dim)\n",
    "        time_cond_dim = dim * 4 * (2 if lowres_cond else 1)\n",
    "\n",
    "        # embedding time for discrete gaussian diffusion or log(snr) noise for continuous version\n",
    "\n",
    "        self.learned_sinu_pos_emb = learned_sinu_pos_emb\n",
    "\n",
    "        if learned_sinu_pos_emb:\n",
    "            sinu_pos_emb = LearnedSinusoidalPosEmb(learned_sinu_pos_emb_dim)\n",
    "            sinu_pos_emb_input_dim = learned_sinu_pos_emb_dim + 1\n",
    "        else:\n",
    "            sinu_pos_emb = SinusoidalPosEmb(dim)\n",
    "            sinu_pos_emb_input_dim = dim\n",
    "\n",
    "        self.to_time_hiddens = nn.Sequential(\n",
    "            sinu_pos_emb,\n",
    "            nn.Linear(sinu_pos_emb_input_dim, time_cond_dim),\n",
    "            nn.SiLU()\n",
    "        )\n",
    "\n",
    "        self.to_time_cond = nn.Sequential(\n",
    "            nn.Linear(time_cond_dim, time_cond_dim)\n",
    "        )\n",
    "\n",
    "        # project to time tokens as well as time hiddens\n",
    "\n",
    "        self.to_time_tokens = nn.Sequential(\n",
    "            nn.Linear(time_cond_dim, cond_dim * num_time_tokens),\n",
    "            Rearrange('b (r d) -> b r d', r = num_time_tokens)\n",
    "        )\n",
    "\n",
    "        # low res aug noise conditioning\n",
    "\n",
    "        self.lowres_cond = lowres_cond\n",
    "\n",
    "        if lowres_cond:\n",
    "            self.to_lowres_time_hiddens = nn.Sequential(\n",
    "                LearnedSinusoidalPosEmb(learned_sinu_pos_emb_dim),\n",
    "                nn.Linear(learned_sinu_pos_emb_dim + 1, time_cond_dim),\n",
    "                nn.SiLU()\n",
    "            )\n",
    "\n",
    "            self.to_lowres_time_cond = nn.Sequential(\n",
    "                nn.Linear(time_cond_dim, time_cond_dim)\n",
    "            )\n",
    "\n",
    "            self.to_lowres_time_tokens = nn.Sequential(\n",
    "                nn.Linear(time_cond_dim, cond_dim * num_time_tokens),\n",
    "                Rearrange('b (r d) -> b r d', r = num_time_tokens)\n",
    "            )\n",
    "\n",
    "        # normalizations\n",
    "\n",
    "        self.norm_cond = nn.LayerNorm(cond_dim)\n",
    "\n",
    "        # text encoding conditioning (optional)\n",
    "\n",
    "        self.text_to_cond = None\n",
    "\n",
    "        if cond_on_text:\n",
    "            assert exists(text_embed_dim), 'text_embed_dim must be given to the unet if cond_on_text is True'\n",
    "            self.text_to_cond = nn.Linear(text_embed_dim, cond_dim)\n",
    "\n",
    "        # finer control over whether to condition on text encodings\n",
    "\n",
    "        self.cond_on_text = cond_on_text\n",
    "\n",
    "        # attention pooling\n",
    "\n",
    "        self.attn_pool = PerceiverResampler(dim = cond_dim, depth = 2, dim_head = attn_dim_head, heads = attn_heads, num_latents = attn_pool_num_latents) if attn_pool_text else None\n",
    "\n",
    "        # for classifier free guidance\n",
    "\n",
    "        self.max_text_len = max_text_len\n",
    "\n",
    "        self.null_text_embed = nn.Parameter(torch.randn(1, max_text_len, cond_dim))\n",
    "        self.null_text_hidden = nn.Parameter(torch.randn(1, time_cond_dim))\n",
    "\n",
    "        # for non-attention based text conditioning at all points in the network where time is also conditioned\n",
    "\n",
    "        self.to_text_non_attn_cond = None\n",
    "\n",
    "        if cond_on_text:\n",
    "            self.to_text_non_attn_cond = nn.Sequential(\n",
    "                nn.LayerNorm(cond_dim),\n",
    "                nn.Linear(cond_dim, time_cond_dim),\n",
    "                nn.SiLU(),\n",
    "                nn.Linear(time_cond_dim, time_cond_dim)\n",
    "            )\n",
    "\n",
    "        # attention related params\n",
    "\n",
    "        attn_kwargs = dict(heads = attn_heads, dim_head = attn_dim_head)\n",
    "\n",
    "        num_layers = len(in_out)\n",
    "\n",
    "        # resnet block klass\n",
    "\n",
    "        num_resnet_blocks = cast_tuple(num_resnet_blocks, num_layers)\n",
    "        resnet_groups = cast_tuple(resnet_groups, num_layers)\n",
    "\n",
    "        layer_attns = cast_tuple(layer_attns, num_layers)\n",
    "        layer_cross_attns = cast_tuple(layer_cross_attns, num_layers)\n",
    "\n",
    "        assert all([layers == num_layers for layers in list(map(len, (resnet_groups, layer_attns, layer_cross_attns)))])\n",
    "\n",
    "        # downsample klass\n",
    "\n",
    "        downsample_klass = DownsampleWithBlur if antialias_downsample else Downsample\n",
    "\n",
    "        if cross_embed_downsample:\n",
    "            downsample_klass = partial(CrossEmbedLayer, kernel_sizes = cross_embed_downsample_kernel_sizes)\n",
    "\n",
    "        # scale for resnet skip connections\n",
    "\n",
    "        self.skip_connect_scale = 1. if not scale_skip_connection else (2 ** -0.5)\n",
    "\n",
    "        # for debugging purposes\n",
    "\n",
    "        self.downsample_concat_hiddens_earlier = downsample_concat_hiddens_earlier\n",
    "\n",
    "        # layers\n",
    "\n",
    "        self.downs = nn.ModuleList([])\n",
    "        self.ups = nn.ModuleList([])\n",
    "        num_resolutions = len(in_out)\n",
    "\n",
    "        layer_params = [num_resnet_blocks, resnet_groups, layer_attns, layer_cross_attns]\n",
    "        reversed_layer_params = list(map(reversed, layer_params))\n",
    "\n",
    "        # downsampling layers\n",
    "\n",
    "        for ind, ((dim_in, dim_out), layer_num_resnet_blocks, groups, layer_attn, layer_cross_attn) in enumerate(zip(in_out, *layer_params)):\n",
    "            is_last = ind >= (num_resolutions - 1)\n",
    "\n",
    "            layer_use_linear_cross_attn = not layer_cross_attn and use_linear_cross_attn\n",
    "            layer_cond_dim = cond_dim if layer_cross_attn or layer_use_linear_cross_attn else None\n",
    "\n",
    "            transformer_block_klass = TransformerBlock if layer_attn else (LinearAttentionTransformerBlock if use_linear_attn else nn.Identity)\n",
    "\n",
    "            self.downs.append(nn.ModuleList([\n",
    "                downsample_klass(dim_in) if memory_efficient else None,\n",
    "                ResnetBlock(dim_in, dim_out, cond_dim = layer_cond_dim, linear_attn = layer_use_linear_cross_attn, time_cond_dim = time_cond_dim, groups = groups),\n",
    "                nn.ModuleList([ResnetBlock(dim_out, dim_out, time_cond_dim = time_cond_dim, groups = groups, use_gca = use_global_context_attn) for _ in range(layer_num_resnet_blocks)]),\n",
    "                transformer_block_klass(dim = dim_out, heads = attn_heads, dim_head = attn_dim_head, ff_mult = ff_mult),\n",
    "                downsample_klass(dim_out) if not memory_efficient and not is_last else None,\n",
    "            ]))\n",
    "\n",
    "        # middle layers\n",
    "\n",
    "        mid_dim = dims[-1]\n",
    "\n",
    "        self.mid_block1 = ResnetBlock(mid_dim, mid_dim, cond_dim = cond_dim, time_cond_dim = time_cond_dim, groups = resnet_groups[-1])\n",
    "        self.mid_attn = EinopsToAndFrom('b c h w', 'b (h w) c', Residual(Attention(mid_dim, **attn_kwargs))) if attend_at_middle else None\n",
    "        self.mid_block2 = ResnetBlock(mid_dim, mid_dim, cond_dim = cond_dim, time_cond_dim = time_cond_dim, groups = resnet_groups[-1])\n",
    "\n",
    "        # upsampling klass\n",
    "\n",
    "        upsample_klass = BilinearUpsample if bilinear_upsample else Upsample\n",
    "\n",
    "        # upsampling layers\n",
    "\n",
    "        for ind, ((dim_in, dim_out), layer_num_resnet_blocks, groups, layer_attn, layer_cross_attn) in enumerate(zip(reversed(in_out), *reversed_layer_params)):\n",
    "            is_last = ind == (len(in_out) - 1)\n",
    "            layer_use_linear_cross_attn = not layer_cross_attn and use_linear_cross_attn\n",
    "            layer_cond_dim = cond_dim if layer_cross_attn or layer_use_linear_cross_attn else None\n",
    "            transformer_block_klass = TransformerBlock if layer_attn else (LinearAttentionTransformerBlock if use_linear_attn else nn.Identity)\n",
    "\n",
    "            self.ups.append(nn.ModuleList([\n",
    "                ResnetBlock(dim_out * 2, dim_in, cond_dim = layer_cond_dim, linear_attn = layer_use_linear_cross_attn, time_cond_dim = time_cond_dim, groups = groups),\n",
    "                nn.ModuleList([ResnetBlock(dim_in, dim_in, time_cond_dim = time_cond_dim, groups = groups, use_gca = use_global_context_attn) for _ in range(layer_num_resnet_blocks)]),\n",
    "                transformer_block_klass(dim = dim_in, heads = attn_heads, dim_head = attn_dim_head, ff_mult = ff_mult),\n",
    "                upsample_klass(dim_in) if not is_last or memory_efficient else nn.Identity()\n",
    "            ]))\n",
    "\n",
    "        # whether to do a final residual from initial conv to the final resnet block out\n",
    "\n",
    "        self.init_conv_to_final_conv_residual = init_conv_to_final_conv_residual\n",
    "        final_conv_dim = dim * (2 if init_conv_to_final_conv_residual else 1)\n",
    "\n",
    "        # final optional resnet block and convolution out\n",
    "\n",
    "        self.final_res_block = ResnetBlock(final_conv_dim, dim, time_cond_dim = time_cond_dim, groups = resnet_groups[0], use_gca = True) if final_resnet_block else None\n",
    "\n",
    "        final_conv_dim_in = dim if final_resnet_block else final_conv_dim\n",
    "        self.final_conv = nn.Conv2d(final_conv_dim_in, self.channels_out, final_conv_kernel_size, padding = final_conv_kernel_size // 2)\n",
    "\n",
    "    # if the current settings for the unet are not correct\n",
    "    # for cascading DDPM, then reinit the unet with the right settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf2d67b-bde6-4eef-b4ba-50c8acaf5d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    def cast_model_parameters(\n",
    "        self,\n",
    "        *,\n",
    "        lowres_cond,\n",
    "        text_embed_dim,\n",
    "        channels,\n",
    "        channels_out,\n",
    "        cond_on_text,\n",
    "        learned_sinu_pos_emb\n",
    "    ):\n",
    "        if lowres_cond == self.lowres_cond and \\\n",
    "            channels == self.channels and \\\n",
    "            cond_on_text == self.cond_on_text and \\\n",
    "            text_embed_dim == self._locals['text_embed_dim'] and \\\n",
    "            learned_sinu_pos_emb == self.learned_sinu_pos_emb and \\\n",
    "            channels_out == self.channels_out:\n",
    "            return self\n",
    "\n",
    "        updated_kwargs = dict(\n",
    "            lowres_cond = lowres_cond,\n",
    "            text_embed_dim = text_embed_dim,\n",
    "            channels = channels,\n",
    "            channels_out = channels_out,\n",
    "            cond_on_text = cond_on_text,\n",
    "            learned_sinu_pos_emb = learned_sinu_pos_emb\n",
    "        )\n",
    "\n",
    "        return self.__class__(**{**self._locals, **updated_kwargs})\n",
    "\n",
    "    def forward_with_cond_scale(\n",
    "        self,\n",
    "        *args,\n",
    "        cond_scale = 1.,\n",
    "        **kwargs\n",
    "    ):\n",
    "        logits = self.forward(*args, **kwargs)\n",
    "\n",
    "        if cond_scale == 1:\n",
    "            return logits\n",
    "\n",
    "        null_logits = self.forward(*args, cond_drop_prob = 1., **kwargs)\n",
    "        return null_logits + (logits - null_logits) * cond_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eafba21-3514-40e1-83bd-a62b98452ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def forward(\n",
    "        self,\n",
    "        x,\n",
    "        time,\n",
    "        *,\n",
    "        lowres_cond_img = None,\n",
    "        lowres_noise_times = None,\n",
    "        text_embeds = None,\n",
    "        text_mask = None,\n",
    "        cond_images = None,\n",
    "        cond_drop_prob = 0.\n",
    "    ):\n",
    "        batch_size, device = x.shape[0], x.device\n",
    "\n",
    "        # add low resolution conditioning, if present\n",
    "\n",
    "        assert not (self.lowres_cond and not exists(lowres_cond_img)), 'low resolution conditioning image must be present'\n",
    "        assert not (self.lowres_cond and not exists(lowres_noise_times)), 'low resolution conditioning noise time must be present'\n",
    "\n",
    "        if exists(lowres_cond_img):\n",
    "            x = torch.cat((x, lowres_cond_img), dim = 1)\n",
    "\n",
    "        # condition on input image\n",
    "\n",
    "        assert not (self.has_cond_image ^ exists(cond_images)), 'you either requested to condition on an image on the unet, but the conditioning image is not supplied, or vice versa'\n",
    "\n",
    "        if exists(cond_images):\n",
    "            assert cond_images.shape[1] == self.cond_images_channels, 'the number of channels on the conditioning image you are passing in does not match what you specified on initialiation of the unet'\n",
    "            cond_images = resize_image_to(cond_images, x.shape[-1])\n",
    "            x = torch.cat((cond_images, x), dim = 1)\n",
    "\n",
    "        # initial convolution\n",
    "\n",
    "        x = self.init_conv(x)\n",
    "\n",
    "        # init conv residual\n",
    "\n",
    "        if self.init_conv_to_final_conv_residual:\n",
    "            init_conv_residual = x.clone()\n",
    "\n",
    "        # time conditioning\n",
    "\n",
    "        time_hiddens = self.to_time_hiddens(time)\n",
    "\n",
    "        # derive time tokens\n",
    "\n",
    "        time_tokens = self.to_time_tokens(time_hiddens)\n",
    "        t = self.to_time_cond(time_hiddens)\n",
    "\n",
    "        # add lowres time conditioning to time hiddens\n",
    "        # and add lowres time tokens along sequence dimension for attention\n",
    "\n",
    "        if self.lowres_cond:\n",
    "            lowres_time_hiddens = self.to_lowres_time_hiddens(lowres_noise_times)\n",
    "            lowres_time_tokens = self.to_lowres_time_tokens(lowres_time_hiddens)\n",
    "            lowres_t = self.to_lowres_time_cond(lowres_time_hiddens)\n",
    "\n",
    "            t = t + lowres_t\n",
    "            time_tokens = torch.cat((time_tokens, lowres_time_tokens), dim = -2)\n",
    "\n",
    "        # text conditioning\n",
    "\n",
    "        text_tokens = None\n",
    "\n",
    "        if exists(text_embeds) and self.cond_on_text:\n",
    "\n",
    "            # conditional dropout\n",
    "\n",
    "            text_keep_mask = prob_mask_like((batch_size,), 1 - cond_drop_prob, device = device)\n",
    "\n",
    "            text_keep_mask_embed = rearrange(text_keep_mask, 'b -> b 1 1')\n",
    "            text_keep_mask_hidden = rearrange(text_keep_mask, 'b -> b 1')\n",
    "\n",
    "            # calculate text embeds\n",
    "\n",
    "            text_tokens = self.text_to_cond(text_embeds)\n",
    "\n",
    "            text_tokens = text_tokens[:, :self.max_text_len]\n",
    "\n",
    "            text_tokens_len = text_tokens.shape[1]\n",
    "            remainder = self.max_text_len - text_tokens_len\n",
    "\n",
    "            if remainder > 0:\n",
    "                text_tokens = F.pad(text_tokens, (0, 0, 0, remainder))\n",
    "\n",
    "            if exists(text_mask):\n",
    "                if remainder > 0:\n",
    "                    text_mask = F.pad(text_mask, (0, remainder), value = False)\n",
    "\n",
    "                text_mask = rearrange(text_mask, 'b n -> b n 1')\n",
    "                text_keep_mask_embed = text_mask & text_keep_mask_embed\n",
    "\n",
    "            null_text_embed = self.null_text_embed.to(text_tokens.dtype) # for some reason pytorch AMP not working\n",
    "\n",
    "            text_tokens = torch.where(\n",
    "                text_keep_mask_embed,\n",
    "                text_tokens,\n",
    "                null_text_embed\n",
    "            )\n",
    "\n",
    "            if exists(self.attn_pool):\n",
    "                text_tokens = self.attn_pool(text_tokens)\n",
    "\n",
    "            # extra non-attention conditioning by projecting and then summing text embeddings to time\n",
    "            # termed as text hiddens\n",
    "\n",
    "            mean_pooled_text_tokens = text_tokens.mean(dim = -2)\n",
    "\n",
    "            text_hiddens = self.to_text_non_attn_cond(mean_pooled_text_tokens)\n",
    "\n",
    "            null_text_hidden = self.null_text_hidden.to(t.dtype)\n",
    "\n",
    "            text_hiddens = torch.where(\n",
    "                text_keep_mask_hidden,\n",
    "                text_hiddens,\n",
    "                null_text_hidden\n",
    "            )\n",
    "\n",
    "            t = t + text_hiddens\n",
    "\n",
    "        # main conditioning tokens (c)\n",
    "\n",
    "        c = time_tokens if not exists(text_tokens) else torch.cat((time_tokens, text_tokens), dim = -2)\n",
    "\n",
    "        # normalize conditioning tokens\n",
    "\n",
    "        c = self.norm_cond(c)\n",
    "\n",
    "        # go through the layers of the unet, down and up\n",
    "\n",
    "        hiddens = []\n",
    "\n",
    "        for pre_downsample, init_block, resnet_blocks, attn_block, post_downsample in self.downs:\n",
    "            if exists(pre_downsample):\n",
    "                x = pre_downsample(x)\n",
    "\n",
    "            x = init_block(x, t, c)\n",
    "\n",
    "            if self.downsample_concat_hiddens_earlier:\n",
    "                hiddens.append(x)\n",
    "\n",
    "            for resnet_block in resnet_blocks:\n",
    "                x = resnet_block(x, t)\n",
    "\n",
    "            x = attn_block(x)\n",
    "\n",
    "            if not self.downsample_concat_hiddens_earlier:\n",
    "                hiddens.append(x)\n",
    "\n",
    "            if exists(post_downsample):\n",
    "                x = post_downsample(x)\n",
    "\n",
    "        x = self.mid_block1(x, t, c)\n",
    "\n",
    "        if exists(self.mid_attn):\n",
    "            x = self.mid_attn(x)\n",
    "\n",
    "        x = self.mid_block2(x, t, c)\n",
    "\n",
    "        for init_block, resnet_blocks, attn_block, upsample in self.ups:\n",
    "\n",
    "            skip_connection = hiddens.pop() * self.skip_connect_scale\n",
    "\n",
    "            x = torch.cat((x, skip_connection), dim = 1)\n",
    "            x = init_block(x, t, c)\n",
    "\n",
    "            for resnet_block in resnet_blocks:\n",
    "                x = resnet_block(x, t)\n",
    "\n",
    "            x = attn_block(x)\n",
    "            x = upsample(x)\n",
    "\n",
    "        # final top-most residual if needed\n",
    "\n",
    "        if self.init_conv_to_final_conv_residual:\n",
    "            x = torch.cat((x, init_conv_residual), dim = 1)\n",
    "\n",
    "        if exists(self.final_res_block):\n",
    "            x = self.final_res_block(x, t)\n",
    "\n",
    "        return self.final_conv(x)\n",
    "\n",
    "# predefined unets, with configs lining up with hyperparameters in appendix of paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1eb5455d-f9a9-4e69-91e5-0b9e0eefe6cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0279, 0.0755, 0.1244, 0.1772, 0.2373, 0.3099, 0.4040, 0.5370, 0.7438,\n",
       "        0.9990], dtype=torch.float64)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BS = BetaSchedule(10)\n",
    "BS.cosine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "544a2dee-fa4a-4834-99d0-c424b3da9854",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0100, 0.2311, 0.4522, 0.6733, 0.8944, 1.1156, 1.3367, 1.5578, 1.7789,\n",
       "        2.0000], dtype=torch.float64)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BS.linear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "63184fea-0430-4442-a7aa-641d0759aebd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0100, 0.2311, 0.4522, 0.6733, 0.8944, 1.1156, 1.3367, 1.5578, 1.7789,\n",
       "        2.0000], dtype=torch.float64)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_beta_schedule(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f50d102e-8d61-47f9-9bec-da5267a81c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "def cosine_beta_schedule(timesteps, s = 0.008, thres = 0.999):\n",
    "    \"\"\"\n",
    "    cosine schedule\n",
    "    as proposed in https://openreview.net/forum?id=-NEXDKk8gZ\n",
    "    \"\"\"\n",
    "    steps = timesteps + 1\n",
    "    \n",
    "    x = torch.linspace(0, timesteps, steps, dtype = torch.float64)\n",
    "    \n",
    "    alphas_cumprod = torch.cos(((x / timesteps) + s) / (1 + s) * torch.pi * 0.5) ** 2\n",
    "    alphas_cumprod = alphas_cumprod / alphas_cumprod[0]\n",
    "    \n",
    "    betas = 1 - (alphas_cumprod[1:] / alphas_cumprod[:-1])\n",
    "    \n",
    "    return torch.clip(betas, 0, thres)\n",
    "\n",
    "def linear_beta_schedule(timesteps):\n",
    "    scale = 1000 / timesteps\n",
    "    beta_start = scale * 0.0001\n",
    "    beta_end = scale * 0.02\n",
    "    return torch.linspace(beta_start, beta_end, timesteps, dtype = torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e31d9f40-4d78-4231-9069-5a69744597ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.linspace(0, 10, 11, dtype = torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7a78ce9-2295-4828-a15a-0652fd59c9fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6.3128e-04, 1.1169e-03, 1.6029e-03, 2.0894e-03, 2.5767e-03, 3.0650e-03,\n",
       "        3.5546e-03, 4.0456e-03, 4.5385e-03, 5.0333e-03, 5.5304e-03, 6.0300e-03,\n",
       "        6.5323e-03, 7.0378e-03, 7.5465e-03, 8.0589e-03, 8.5751e-03, 9.0955e-03,\n",
       "        9.6205e-03, 1.0150e-02, 1.0685e-02, 1.1226e-02, 1.1772e-02, 1.2324e-02,\n",
       "        1.2883e-02, 1.3449e-02, 1.4023e-02, 1.4604e-02, 1.5193e-02, 1.5791e-02,\n",
       "        1.6399e-02, 1.7016e-02, 1.7643e-02, 1.8282e-02, 1.8931e-02, 1.9593e-02,\n",
       "        2.0268e-02, 2.0956e-02, 2.1658e-02, 2.2376e-02, 2.3109e-02, 2.3859e-02,\n",
       "        2.4627e-02, 2.5413e-02, 2.6219e-02, 2.7047e-02, 2.7897e-02, 2.8770e-02,\n",
       "        2.9668e-02, 3.0593e-02, 3.1546e-02, 3.2530e-02, 3.3545e-02, 3.4594e-02,\n",
       "        3.5680e-02, 3.6805e-02, 3.7971e-02, 3.9182e-02, 4.0441e-02, 4.1751e-02,\n",
       "        4.3116e-02, 4.4541e-02, 4.6030e-02, 4.7588e-02, 4.9221e-02, 5.0936e-02,\n",
       "        5.2740e-02, 5.4640e-02, 5.6646e-02, 5.8768e-02, 6.1018e-02, 6.3407e-02,\n",
       "        6.5952e-02, 6.8669e-02, 7.1578e-02, 7.4701e-02, 7.8065e-02, 8.1700e-02,\n",
       "        8.5642e-02, 8.9935e-02, 9.4629e-02, 9.9786e-02, 1.0548e-01, 1.1181e-01,\n",
       "        1.1888e-01, 1.2683e-01, 1.3586e-01, 1.4620e-01, 1.5815e-01, 1.7215e-01,\n",
       "        1.8875e-01, 2.0879e-01, 2.3344e-01, 2.6453e-01, 3.0494e-01, 3.5953e-01,\n",
       "        4.3718e-01, 5.5538e-01, 7.4994e-01, 9.9900e-01], dtype=torch.float64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_beta_schedule(100, s = 0.008, thres = 0.999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3a3e5c32-5bfd-43c9-9bd0-0d72834752f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BetaSchedule():\n",
    "    \n",
    "    def __init__(self, timestep):\n",
    "        self.timestep = timestep\n",
    "    \n",
    "    def cosine(self, s = 0.008, threshold = 0.999): # https://openreview.net/forum?id=-NEXDKk8gZ\n",
    "                \n",
    "        x = torch.linspace(0, self.timestep, self.timestep+1, dtype=torch.float64)\n",
    "        f = ((x / self.timestep) + s) / (1 + s)\n",
    "        w = 0.5 * torch.pi * f\n",
    "        \n",
    "        a = torch.cos(w)**2\n",
    "        a = a / a[0]\n",
    "        \n",
    "        b = 1 - (a[1:]/a[:-1])\n",
    "        \n",
    "        return torch.clip(b, 0, threshold)\n",
    "        \n",
    "    def linear(self):\n",
    "\n",
    "        b_start = 0.1  / self.timestep\n",
    "        b_end   = 20.0 / self.timestep\n",
    "    \n",
    "        return torch.linspace(b_start, b_end, self.timestep, dtype=torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "13d39876-8072-46e9-b5fd-34fb7038fcad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0250, 1.6833, 3.3417, 5.0000], dtype=torch.float64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_beta_schedule(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "931ab01a-18c6-4d4f-9ff9-3dbca1e7ea35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0250, 1.6833, 3.3417, 5.0000], dtype=torch.float64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GaussianDiffusion()"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GaussianDiffusion(noise_type='linear', timesteps=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "829ad993-9bfe-4344-a299-8e385e56db84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0279, 0.0755, 0.1244, 0.1772, 0.2373, 0.3099, 0.4040, 0.5370, 0.7438,\n",
       "        0.9990], dtype=torch.float64)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_beta_schedule(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "36a90602-9a06-44bb-a093-a23a3c253079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0279, 0.0755, 0.1244, 0.1772, 0.2373, 0.3099, 0.4040, 0.5370, 0.7438,\n",
      "        0.9990], dtype=torch.float64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GaussianDiffusion()"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GaussianDiffusion(timesteps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "51b5cf4f-9199-4f95-a91f-1b1a6043c800",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 10\n",
    "(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5682bc2f-91d3-481a-b484-867d6696a4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class GaussianDiffusion(nn.Module):\n",
    "    \n",
    "    def __init__(self, noise_type='cosine', timesteps=1000):\n",
    "        \n",
    "        super(GaussianDiffusion, self).__init__()\n",
    "        \n",
    "        self.timesteps = timesteps\n",
    "        \n",
    "        BS = BetaSchedule(timesteps)\n",
    "        \n",
    "        betas  = BS.cosine() if 'cosine'==noise_type else BS.linear()        \n",
    "        alphas = 1 - betas\n",
    "        \n",
    "        alphas_cumprod      = torch.cumprod(alphas, axis = 0)\n",
    "        alphas_cumprod_prev = F.pad(alphas_cumprod[:-1], (1, 0), value = 1)\n",
    "        \n",
    "        register_buffer = lambda name, val: self.register_buffer(name, val.to(torch.float32), persistent = False)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f24b810-867b-4fea-a85f-eb7faca09f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianDiffusionContinuousTimes(nn.Module):\n",
    "    def __init__(self, *, noise_schedule, timesteps):\n",
    "        super().__init__()\n",
    "        if noise_schedule == 'linear':\n",
    "            self.log_snr = beta_linear_log_snr\n",
    "        elif noise_schedule == \"cosine\":\n",
    "            self.log_snr = alpha_cosine_log_snr\n",
    "        else:\n",
    "            raise ValueError(f'invalid noise schedule {noise_schedule}')\n",
    "\n",
    "        self.num_timesteps = timesteps\n",
    "\n",
    "    def get_times(self, batch_size, noise_level, *, device):\n",
    "        return torch.full((batch_size,), noise_level, device = device, dtype = torch.long)\n",
    "\n",
    "    def sample_random_times(self, batch_size, max_thres = 0.999, *, device):\n",
    "        return torch.zeros((batch_size,), device = device).float().uniform_(0, max_thres)\n",
    "\n",
    "    def get_condition(self, times):\n",
    "        return maybe(self.log_snr)(times)\n",
    "\n",
    "    def get_sampling_timesteps(self, batch, *, device):\n",
    "        times = torch.linspace(1., 0., self.num_timesteps + 1, device = device)\n",
    "        times = repeat(times, 't -> b t', b = batch)\n",
    "        times = torch.stack((times[:, :-1], times[:, 1:]), dim = 0)\n",
    "        times = times.unbind(dim = -1)\n",
    "        return times\n",
    "\n",
    "    def q_posterior(self, x_start, x_t, t, *, t_next = None):\n",
    "        t_next = default(t_next, lambda: (t - 1. / self.num_timesteps).clamp(min = 0.))\n",
    "\n",
    "        \"\"\" https://openreview.net/attachment?id=2LdBqxc1Yv&name=supplementary_material \"\"\"\n",
    "        log_snr = self.log_snr(t)\n",
    "        log_snr_next = self.log_snr(t_next)\n",
    "        log_snr, log_snr_next = map(partial(right_pad_dims_to, x_t), (log_snr, log_snr_next))\n",
    "\n",
    "        alpha, sigma = log_snr_to_alpha_sigma(log_snr)\n",
    "        alpha_next, sigma_next = log_snr_to_alpha_sigma(log_snr_next)\n",
    "\n",
    "        # c - as defined near eq 33\n",
    "        c = -expm1(log_snr - log_snr_next)\n",
    "        posterior_mean = alpha_next * (x_t * (1 - c) / alpha + c * x_start)\n",
    "\n",
    "        # following (eq. 33)\n",
    "        posterior_variance = (sigma_next ** 2) * c\n",
    "        posterior_log_variance_clipped = log(posterior_variance, eps = 1e-20)\n",
    "        return posterior_mean, posterior_variance, posterior_log_variance_clipped\n",
    "\n",
    "    def q_sample(self, x_start, t, noise = None):\n",
    "        noise = default(noise, lambda: torch.randn_like(x_start))\n",
    "        log_snr = self.log_snr(t)\n",
    "        log_snr_padded_dim = right_pad_dims_to(x_start, log_snr)\n",
    "        alpha, sigma =  log_snr_to_alpha_sigma(log_snr_padded_dim)\n",
    "        return alpha * x_start + sigma * noise, log_snr\n",
    "\n",
    "    def predict_start_from_noise(self, x_t, t, noise):\n",
    "        log_snr = self.log_snr(t)\n",
    "        log_snr = right_pad_dims_to(x_t, log_snr)\n",
    "        alpha, sigma = log_snr_to_alpha_sigma(log_snr)\n",
    "        return (x_t - sigma * noise) / alpha.clamp(min = 1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "34482079-1ee5-4922-ba51-975f1009f683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GaussianDiffusion()"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GaussianDiffusion(timesteps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b452db92-8813-4461-9f43-a8116681a36c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0000, 0.9721, 0.8987, 0.7869, 0.6475, 0.4938, 0.3408, 0.2031, 0.0940,\n",
      "        0.0241], dtype=torch.float64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GaussianDiffusion()"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GaussianDiffusion(timesteps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cfbaf6f5-afa8-4426-ab9e-9d06019a63e3",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "<lambda>() got an unexpected keyword argument 'persistent'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [50]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m register_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m name, val: register_buffer(name, val\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat32), persistent \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m----> 3\u001b[0m \u001b[43mregister_buffer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbetas\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m41\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m register_buffer(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124malphas_cumprod\u001b[39m\u001b[38;5;124m'\u001b[39m, torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;241m51\u001b[39m))\n",
      "Input \u001b[1;32mIn [50]\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(name, val)\u001b[0m\n\u001b[1;32m----> 1\u001b[0m register_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m name, val: \u001b[43mregister_buffer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpersistent\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m register_buffer(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m'\u001b[39m, torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;241m41\u001b[39m))\n\u001b[0;32m      4\u001b[0m register_buffer(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124malphas_cumprod\u001b[39m\u001b[38;5;124m'\u001b[39m, torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;241m51\u001b[39m))\n",
      "\u001b[1;31mTypeError\u001b[0m: <lambda>() got an unexpected keyword argument 'persistent'"
     ]
    }
   ],
   "source": [
    "register_buffer = lambda name, val: register_buffer(name, val.to(torch.float32), persistent = False)\n",
    "\n",
    "register_buffer('betas', torch.tensor(41))\n",
    "register_buffer('alphas_cumprod', torch.tensor(51))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be68fb6-0ea1-43a2-a92d-6c8a29d3a114",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianDiffusion(nn.Module):\n",
    "    def __init__(self, *, noise_schedule, timesteps):\n",
    "        super().__init__()\n",
    "\n",
    "        if noise_schedule == \"cosine\":\n",
    "            betas = cosine_beta_schedule(timesteps)\n",
    "        elif noise_schedule == \"linear\":\n",
    "            betas = linear_beta_schedule(timesteps)\n",
    "        else:\n",
    "            raise NotImplementedError()\n",
    "\n",
    "        alphas = 1. - betas\n",
    "        alphas_cumprod = torch.cumprod(alphas, axis = 0)\n",
    "        alphas_cumprod_prev = F.pad(alphas_cumprod[:-1], (1, 0), value = 1.)\n",
    "\n",
    "        timesteps, = betas.shape\n",
    "        self.num_timesteps = int(timesteps)\n",
    "\n",
    "        # register buffer helper function to cast double back to float\n",
    "\n",
    "        register_buffer = lambda name, val: self.register_buffer(name, val.to(torch.float32), persistent = False)\n",
    "\n",
    "        register_buffer('betas', betas)\n",
    "        register_buffer('alphas_cumprod', alphas_cumprod)\n",
    "        register_buffer('alphas_cumprod_prev', alphas_cumprod_prev)\n",
    "\n",
    "        # calculations for diffusion q(x_t | x_{t-1}) and others\n",
    "\n",
    "        register_buffer('sqrt_alphas_cumprod', torch.sqrt(alphas_cumprod))\n",
    "        register_buffer('sqrt_one_minus_alphas_cumprod', torch.sqrt(1. - alphas_cumprod))\n",
    "        register_buffer('log_one_minus_alphas_cumprod', torch.log(1. - alphas_cumprod))\n",
    "        register_buffer('sqrt_recip_alphas_cumprod', torch.sqrt(1. / alphas_cumprod))\n",
    "        register_buffer('sqrt_recipm1_alphas_cumprod', torch.sqrt(1. / alphas_cumprod - 1))\n",
    "\n",
    "        # calculations for posterior q(x_{t-1} | x_t, x_0)\n",
    "\n",
    "        posterior_variance = betas * (1. - alphas_cumprod_prev) / (1. - alphas_cumprod)\n",
    "\n",
    "        # above: equal to 1. / (1. / (1. - alpha_cumprod_tm1) + alpha_t / beta_t)\n",
    "\n",
    "        register_buffer('posterior_variance', posterior_variance)\n",
    "\n",
    "        # below: log calculation clipped because the posterior variance is 0 at the beginning of the diffusion chain\n",
    "\n",
    "        register_buffer('posterior_log_variance_clipped', log(posterior_variance, eps = 1e-20))\n",
    "        register_buffer('posterior_mean_coef1', betas * torch.sqrt(alphas_cumprod_prev) / (1. - alphas_cumprod))\n",
    "        register_buffer('posterior_mean_coef2', (1. - alphas_cumprod_prev) * torch.sqrt(alphas) / (1. - alphas_cumprod))\n",
    "\n",
    "    def get_times(self, batch_size, noise_level, *, device):\n",
    "        return torch.full((batch_size,), int(self.num_timesteps * noise_level), device = device, dtype = torch.long)\n",
    "\n",
    "    def sample_random_times(self, batch_size, *, device):\n",
    "        return torch.randint(0, self.num_timesteps, (batch_size,), device = device, dtype = torch.long)\n",
    "\n",
    "    def get_condition(self, times):\n",
    "        return times\n",
    "\n",
    "    def get_sampling_timesteps(self, batch, *, device):\n",
    "        time_transitions = []\n",
    "\n",
    "        for i in reversed(range(self.num_timesteps)):\n",
    "            time_transitions.append((torch.full((batch,), i, device = device, dtype = torch.long), None))\n",
    "\n",
    "        return time_transitions\n",
    "\n",
    "    def q_posterior(self, x_start, x_t, t, **kwargs):\n",
    "        posterior_mean = (\n",
    "            extract(self.posterior_mean_coef1, t, x_t.shape) * x_start +\n",
    "            extract(self.posterior_mean_coef2, t, x_t.shape) * x_t\n",
    "        )\n",
    "        posterior_variance = extract(self.posterior_variance, t, x_t.shape)\n",
    "        posterior_log_variance_clipped = extract(self.posterior_log_variance_clipped, t, x_t.shape)\n",
    "        return posterior_mean, posterior_variance, posterior_log_variance_clipped\n",
    "\n",
    "    def q_sample(self, x_start, t, noise = None):\n",
    "        noise = default(noise, lambda: torch.randn_like(x_start))\n",
    "\n",
    "        noised = (\n",
    "            extract(self.sqrt_alphas_cumprod, t, x_start.shape) * x_start +\n",
    "            extract(self.sqrt_one_minus_alphas_cumprod, t, x_start.shape) * noise\n",
    "        )\n",
    "\n",
    "        alphas_cumprod = extract(self.alphas_cumprod, t, t.shape)\n",
    "        log_snr = -log(1. / alphas_cumprod - 1)\n",
    "\n",
    "        return noised, log_snr\n",
    "\n",
    "    def predict_start_from_noise(self, x_t, t, noise):\n",
    "        return (\n",
    "            extract(self.sqrt_recip_alphas_cumprod, t, x_t.shape) * x_t -\n",
    "            extract(self.sqrt_recipm1_alphas_cumprod, t, x_t.shape) * noise\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2721089a-82cb-4c42-a9b7-b7a279226395",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exists(val):\n",
    "    return val is not None\n",
    "\n",
    "def default(val, d):\n",
    "    if exists(val):\n",
    "        return val\n",
    "    return d() if callable(d) else d\n",
    "\n",
    "def cast_tuple(val, length = None):\n",
    "    if isinstance(val, list):\n",
    "        val = tuple(val)\n",
    "\n",
    "    output = val if isinstance(val, tuple) else ((val,) * default(length, 1))\n",
    "\n",
    "    if exists(length):\n",
    "        assert len(output) == length\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9d6877b-3fb0-4099-a112-971dbf68a4b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 1000)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cast_tuple(1000, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f8d1b7-7dfc-443c-8628-655228fd6dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianDiffusionContinuousTimes(nn.Module):\n",
    "    def __init__(self, *, noise_schedule, timesteps):\n",
    "        super().__init__()\n",
    "        if noise_schedule == 'linear':\n",
    "            self.log_snr = beta_linear_log_snr\n",
    "        elif noise_schedule == \"cosine\":\n",
    "            self.log_snr = alpha_cosine_log_snr\n",
    "        else:\n",
    "            raise ValueError(f'invalid noise schedule {noise_schedule}')\n",
    "\n",
    "        self.num_timesteps = timesteps\n",
    "\n",
    "    def get_times(self, batch_size, noise_level, *, device):\n",
    "        return torch.full((batch_size,), noise_level, device = device, dtype = torch.long)\n",
    "\n",
    "    def sample_random_times(self, batch_size, max_thres = 0.999, *, device):\n",
    "        return torch.zeros((batch_size,), device = device).float().uniform_(0, max_thres)\n",
    "\n",
    "    def get_condition(self, times):\n",
    "        return maybe(self.log_snr)(times)\n",
    "\n",
    "    def get_sampling_timesteps(self, batch, *, device):\n",
    "        times = torch.linspace(1., 0., self.num_timesteps + 1, device = device)\n",
    "        times = repeat(times, 't -> b t', b = batch)\n",
    "        times = torch.stack((times[:, :-1], times[:, 1:]), dim = 0)\n",
    "        times = times.unbind(dim = -1)\n",
    "        return times\n",
    "\n",
    "    def q_posterior(self, x_start, x_t, t, *, t_next = None):\n",
    "        t_next = default(t_next, lambda: (t - 1. / self.num_timesteps).clamp(min = 0.))\n",
    "\n",
    "        \"\"\" https://openreview.net/attachment?id=2LdBqxc1Yv&name=supplementary_material \"\"\"\n",
    "        log_snr = self.log_snr(t)\n",
    "        log_snr_next = self.log_snr(t_next)\n",
    "        log_snr, log_snr_next = map(partial(right_pad_dims_to, x_t), (log_snr, log_snr_next))\n",
    "\n",
    "        alpha, sigma = log_snr_to_alpha_sigma(log_snr)\n",
    "        alpha_next, sigma_next = log_snr_to_alpha_sigma(log_snr_next)\n",
    "\n",
    "        # c - as defined near eq 33\n",
    "        c = -expm1(log_snr - log_snr_next)\n",
    "        posterior_mean = alpha_next * (x_t * (1 - c) / alpha + c * x_start)\n",
    "\n",
    "        # following (eq. 33)\n",
    "        posterior_variance = (sigma_next ** 2) * c\n",
    "        posterior_log_variance_clipped = log(posterior_variance, eps = 1e-20)\n",
    "        return posterior_mean, posterior_variance, posterior_log_variance_clipped\n",
    "\n",
    "    def q_sample(self, x_start, t, noise = None):\n",
    "        noise = default(noise, lambda: torch.randn_like(x_start))\n",
    "        log_snr = self.log_snr(t)\n",
    "        log_snr_padded_dim = right_pad_dims_to(x_start, log_snr)\n",
    "        alpha, sigma =  log_snr_to_alpha_sigma(log_snr_padded_dim)\n",
    "        return alpha * x_start + sigma * noise, log_snr\n",
    "\n",
    "    def predict_start_from_noise(self, x_t, t, noise):\n",
    "        log_snr = self.log_snr(t)\n",
    "        log_snr = right_pad_dims_to(x_t, log_snr)\n",
    "        alpha, sigma = log_snr_to_alpha_sigma(log_snr)\n",
    "        return (x_t - sigma * noise) / alpha.clamp(min = 1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9e67cbf-cc21-4836-895f-75de1ff42d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.special import expm1\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "05310659-5eb2-4947-85f0-3be81a5c6ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BetaSchedule():\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def cosine(self, t, s: float = 0.008):\n",
    "                \n",
    "        f = (t + s) / (1 + s)\n",
    "        w = f * math.pi * 0.5\n",
    "        c = (torch.cos(w) ** -2) - 1\n",
    "\n",
    "        return -torch.log(c.clamp(min = 1e-5))\n",
    "        \n",
    "    def linear(self, t):\n",
    "        \n",
    "        xi = 1e-4 + 10 * (t ** 2)\n",
    "        y  = torch.exp(xi) - 1\n",
    "    \n",
    "        return -torch.log(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ff1df814-5f05-4ef5-bf13-926731cc694f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.2511)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BS = BetaSchedule()\n",
    "BS.linear(torch.tensor(0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "639a8e99-4f1b-4b34-bf03-454a8cc46cd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.5450)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BS = BetaSchedule()\n",
    "BS.cosine(torch.tensor(0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74c74c11-93fb-4214-ad1b-0dd8b12fd465",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.jit.script\n",
    "def beta_linear_log_snr(t):\n",
    "    return -torch.log(expm1())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f96ff92-d6b2-4b0d-a8c8-19572b94a510",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log(t, eps: float = 1e-12):\n",
    "    return torch.log(t.clamp(min = eps))\n",
    "\n",
    "@torch.jit.script\n",
    "def alpha_cosine_log_snr(t, s: float = 0.008):\n",
    "    return -log((torch.cos((t + s) / (1 + s) * math.pi * 0.5) ** -2) - 1, eps = 1e-5) # not sure if this accounts for beta being clipped to 0.999 in discrete version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "20f51ca7-5404-46d1-b6d3-800742c1eeb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.2511)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta_linear_log_snr(torch.tensor(0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "24ca4fd8-d8fe-4589-97f7-78ecdfcd29b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.5450)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_cosine_log_snr(torch.tensor(0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fd37284c-5053-43ba-8b55-5a5ab77de6ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-4.1539)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_cosine_log_snr(torch.tensor(11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f090ce1f-4cf4-454d-8b9b-caf14c892e1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-4.1539)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def teste():\n",
    "    \n",
    "    \n",
    "\n",
    "teste(torch.tensor(11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d26b91-8127-4e12-a73b-c5d9995483e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def q_posterior(self, x_start, x_t, t, *, t_next = None):\n",
    "        t_next = default(t_next, lambda: (t - 1. / self.num_timesteps).clamp(min = 0.))\n",
    "\n",
    "        \"\"\" https://openreview.net/attachment?id=2LdBqxc1Yv&name=supplementary_material \"\"\"\n",
    "        log_snr = self.log_snr(t)\n",
    "        log_snr_next = self.log_snr(t_next)\n",
    "        log_snr, log_snr_next = map(partial(right_pad_dims_to, x_t), (log_snr, log_snr_next))\n",
    "\n",
    "        alpha, sigma = log_snr_to_alpha_sigma(log_snr)\n",
    "        alpha_next, sigma_next = log_snr_to_alpha_sigma(log_snr_next)\n",
    "\n",
    "        # c - as defined near eq 33\n",
    "        c = -expm1(log_snr - log_snr_next)\n",
    "        posterior_mean = alpha_next * (x_t * (1 - c) / alpha + c * x_start)\n",
    "\n",
    "        # following (eq. 33)\n",
    "        posterior_variance = (sigma_next ** 2) * c\n",
    "        posterior_log_variance_clipped = log(posterior_variance, eps = 1e-20)\n",
    "        return posterior_mean, posterior_variance, posterior_log_variance_clipped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "77d66c2f-d96a-4263-aacb-dcb2441816b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sampling loop time step:   0%|          | 0/3 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable int object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [25]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[0;32m      2\u001b[0m timesteps \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m1000\u001b[39m, \u001b[38;5;241m20\u001b[39m, \u001b[38;5;241m30\u001b[39m]\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m times, times_next \u001b[38;5;129;01min\u001b[39;00m tqdm(timesteps, desc \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msampling loop time step\u001b[39m\u001b[38;5;124m'\u001b[39m, total \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(timesteps)):\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(times, times_next)\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot unpack non-iterable int object"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "timesteps = [1000, 20, 30]\n",
    "\n",
    "for times, times_next in tqdm(timesteps, desc = 'sampling loop time step', total = len(timesteps)):\n",
    "    print(times, times_next)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5df13d1f-d865-4ab7-8f6b-fbfb7da6c40e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 3, 3, 3])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.full((4,), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "30432cf7-8321-4a82-877a-975069795945",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1.0000, 1.0000, 1.0000],\n",
       "         [0.9000, 0.9000, 0.9000]]),\n",
       " tensor([[0.9000, 0.9000, 0.9000],\n",
       "         [0.8000, 0.8000, 0.8000]]),\n",
       " tensor([[0.8000, 0.8000, 0.8000],\n",
       "         [0.7000, 0.7000, 0.7000]]),\n",
       " tensor([[0.7000, 0.7000, 0.7000],\n",
       "         [0.6000, 0.6000, 0.6000]]),\n",
       " tensor([[0.6000, 0.6000, 0.6000],\n",
       "         [0.5000, 0.5000, 0.5000]]),\n",
       " tensor([[0.5000, 0.5000, 0.5000],\n",
       "         [0.4000, 0.4000, 0.4000]]),\n",
       " tensor([[0.4000, 0.4000, 0.4000],\n",
       "         [0.3000, 0.3000, 0.3000]]),\n",
       " tensor([[0.3000, 0.3000, 0.3000],\n",
       "         [0.2000, 0.2000, 0.2000]]),\n",
       " tensor([[0.2000, 0.2000, 0.2000],\n",
       "         [0.1000, 0.1000, 0.1000]]),\n",
       " tensor([[0.1000, 0.1000, 0.1000],\n",
       "         [0.0000, 0.0000, 0.0000]]))"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "times = torch.linspace(1., 0., 10 + 1)\n",
    "\n",
    "for i in range(len(times)-1):\n",
    "    \n",
    "    j = torch.stack((torch.full((3,), times[i]),torch.full((3,), times[i+1])), dim = 0)\n",
    "    # print(j)\n",
    "    \n",
    "j = tuple([torch.stack((torch.full((3,), times[i]),torch.full((3,), times[i+1])), dim = 0) for i in range(len(times)-1)])\n",
    "j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "59922bcb-be53-408f-9360-33c45cd85a1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[True, True, True],\n",
      "        [True, True, True]])\n",
      "tensor([[True, True, True],\n",
      "        [True, True, True]])\n",
      "tensor([[True, True, True],\n",
      "        [True, True, True]])\n",
      "tensor([[True, True, True],\n",
      "        [True, True, True]])\n",
      "tensor([[True, True, True],\n",
      "        [True, True, True]])\n",
      "tensor([[True, True, True],\n",
      "        [True, True, True]])\n",
      "tensor([[True, True, True],\n",
      "        [True, True, True]])\n",
      "tensor([[True, True, True],\n",
      "        [True, True, True]])\n",
      "tensor([[True, True, True],\n",
      "        [True, True, True]])\n",
      "tensor([[True, True, True],\n",
      "        [True, True, True]])\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(torch.eq(j[i], t[i]))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "aefa9541-2a02-4e0e-82e6-1620ee77e03a",
   "metadata": {},
   "source": [
    "torch.full((4,), times[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "bea6a1cb-609d-45e8-85a0-b4761de07104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0000, 0.9000, 0.8000, 0.7000, 0.6000, 0.5000, 0.4000, 0.3000, 0.2000,\n",
      "        0.1000, 0.0000]) \n",
      "\n",
      "tensor([[1.0000, 0.9000, 0.8000, 0.7000, 0.6000, 0.5000, 0.4000, 0.3000, 0.2000,\n",
      "         0.1000, 0.0000],\n",
      "        [1.0000, 0.9000, 0.8000, 0.7000, 0.6000, 0.5000, 0.4000, 0.3000, 0.2000,\n",
      "         0.1000, 0.0000],\n",
      "        [1.0000, 0.9000, 0.8000, 0.7000, 0.6000, 0.5000, 0.4000, 0.3000, 0.2000,\n",
      "         0.1000, 0.0000]]) \n",
      "\n",
      "tensor([[[1.0000, 0.9000, 0.8000, 0.7000, 0.6000, 0.5000, 0.4000, 0.3000,\n",
      "          0.2000, 0.1000],\n",
      "         [1.0000, 0.9000, 0.8000, 0.7000, 0.6000, 0.5000, 0.4000, 0.3000,\n",
      "          0.2000, 0.1000],\n",
      "         [1.0000, 0.9000, 0.8000, 0.7000, 0.6000, 0.5000, 0.4000, 0.3000,\n",
      "          0.2000, 0.1000]],\n",
      "\n",
      "        [[0.9000, 0.8000, 0.7000, 0.6000, 0.5000, 0.4000, 0.3000, 0.2000,\n",
      "          0.1000, 0.0000],\n",
      "         [0.9000, 0.8000, 0.7000, 0.6000, 0.5000, 0.4000, 0.3000, 0.2000,\n",
      "          0.1000, 0.0000],\n",
      "         [0.9000, 0.8000, 0.7000, 0.6000, 0.5000, 0.4000, 0.3000, 0.2000,\n",
      "          0.1000, 0.0000]]]) \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[1.0000, 1.0000, 1.0000],\n",
       "         [0.9000, 0.9000, 0.9000]]),\n",
       " tensor([[0.9000, 0.9000, 0.9000],\n",
       "         [0.8000, 0.8000, 0.8000]]),\n",
       " tensor([[0.8000, 0.8000, 0.8000],\n",
       "         [0.7000, 0.7000, 0.7000]]),\n",
       " tensor([[0.7000, 0.7000, 0.7000],\n",
       "         [0.6000, 0.6000, 0.6000]]),\n",
       " tensor([[0.6000, 0.6000, 0.6000],\n",
       "         [0.5000, 0.5000, 0.5000]]),\n",
       " tensor([[0.5000, 0.5000, 0.5000],\n",
       "         [0.4000, 0.4000, 0.4000]]),\n",
       " tensor([[0.4000, 0.4000, 0.4000],\n",
       "         [0.3000, 0.3000, 0.3000]]),\n",
       " tensor([[0.3000, 0.3000, 0.3000],\n",
       "         [0.2000, 0.2000, 0.2000]]),\n",
       " tensor([[0.2000, 0.2000, 0.2000],\n",
       "         [0.1000, 0.1000, 0.1000]]),\n",
       " tensor([[0.1000, 0.1000, 0.1000],\n",
       "         [0.0000, 0.0000, 0.0000]]))"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from einops import rearrange, repeat, reduce\n",
    "def get_sampling_timesteps(batch):\n",
    "    times = torch.linspace(1., 0., 10 + 1)\n",
    "    print(times, '\\n')\n",
    "    times = repeat(times, 't -> b t', b = batch)\n",
    "    print(times, '\\n')\n",
    "    times = torch.stack((times[:, :-1], times[:, 1:]), dim = 0)\n",
    "    print(times, '\\n')\n",
    "    times = times.unbind(dim = -1)\n",
    "    return times\n",
    "\n",
    "t = get_sampling_timesteps(3)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "05a263d6-0881-4891-8031-3c6ec4d8126c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 1.0000, 1.0000],\n",
       "        [0.9000, 0.9000, 0.9000]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9f2e6fb8-d3b2-43a5-95e2-7131cd50dd0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9990, 0.9990, 0.9990, 0.9990, 0.9990, 0.9990, 0.9990, 0.9990, 0.9990,\n",
       "         0.9990],\n",
       "        [0.9980, 0.9980, 0.9980, 0.9980, 0.9980, 0.9980, 0.9980, 0.9980, 0.9980,\n",
       "         0.9980]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5917e3-783f-4b05-80ed-fa9271922d82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09be1a0-1340-4819-a697-7378046bbdb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab96e1b3-9a31-4d14-9451-dc2aad8b65ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a2e2205d-9657-4856-9169-6ede614c618a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def t_equal_x_dim(x, t):\n",
    "    padding_dims = x.ndim - t.ndim\n",
    "    \n",
    "    if padding_dims <= 0:\n",
    "        return t\n",
    "    return t.view(*t.shape, *((1,) * padding_dims))\n",
    "\n",
    "class GaussianDiffusion(nn.Module):\n",
    "    \n",
    "    def __init__(self, noise_type='cosine', timesteps=1000, device='cpu'):\n",
    "        \n",
    "        super(GaussianDiffusion, self).__init__()\n",
    "        \n",
    "        BS = BetaSchedule()   \n",
    "        \n",
    "        self.timesteps = timesteps      \n",
    "        self.snr_func  = BS.cosine if 'cosine'==noise_type else BS.linear    \n",
    "        self.device    = device\n",
    "        \n",
    "    def get_times(self, batch_size, noise_level):\n",
    "        return torch.full((batch_size,), noise_level, device=self.device, dtype=torch.long)\n",
    "    \n",
    "    def sample_random_times(self, batch_size, max_threshold = 0.999):\n",
    "        return torch.zeros((batch_size,), device=self.device).float().uniform_(0, max_threshold)\n",
    "    \n",
    "    def get_condition(self, times):\n",
    "        return self.beta(times)\n",
    "    \n",
    "    def get_sampling_timesteps(self, batch):\n",
    "        times = torch.linspace(1., 0., self.timesteps + 1, device = self.device)\n",
    "        return tuple([torch.stack((torch.full((batch,), times[i]),torch.full((batch,), times[i+1])), dim = 0) for i in range(len(times)-1)])\n",
    "    \n",
    "    def snr_to_alpha_sigma(self, log_snr):\n",
    "        return torch.sqrt(torch.sigmoid(log_snr)), torch.sqrt(torch.sigmoid(-log_snr))\n",
    "\n",
    "    def q_posterior(self, x_start, x_t, t, t_next):\n",
    "\n",
    "        snr      = self.snr_func(t)\n",
    "        snr_next = self.snr_func(t_next)\n",
    "\n",
    "        log_snr, log_snr_next = map(partial(t_equal_x_dim, x_t), (log_snr, log_snr_next))\n",
    "\n",
    "        alpha, sigma           = log_snr_to_alpha_sigma(log_snr)\n",
    "        alpha_next, sigma_next = log_snr_to_alpha_sigma(log_snr_next)\n",
    "\n",
    "        c      = 1 - torch.exp(log_snr - log_snr_next)\n",
    "        p_mean = alpha_next * (x_t * (1 - c) / alpha + c * x_start)\n",
    "\n",
    "        p_variance     = (sigma_next ** 2) * c\n",
    "        p_log_variance = log(p_variance, eps = 1e-20)\n",
    "        p_log_variance = torch.log(p_variance.clamp(min = 1e-20))\n",
    "\n",
    "        return p_mean, p_variance, p_log_variance\n",
    "    \n",
    "    def q_sample(self, x_start, t, noise):\n",
    "        \n",
    "        snr = self.snr_func(t)\n",
    "        \n",
    "        snr          = t_equal_x_dim(x_start, snr)\n",
    "        alpha, sigma = log_snr_to_alpha_sigma(snr)\n",
    "        \n",
    "        return alpha * x_start + sigma * noise, snr\n",
    "    \n",
    "    def predict_start_from_noise(self, x_t, t, noise):\n",
    "        \n",
    "        snr = self.snr_func(t)\n",
    "        \n",
    "        snr          = t_equal_x_dim(x_t, snr)\n",
    "        alpha, sigma = log_snr_to_alpha_sigma(snr)\n",
    "        \n",
    "        return (x_t - sigma * noise) / alpha.clamp(min = 1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "17c5e533-c91e-48d0-8099-f8184fda1703",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1.0000, 1.0000, 1.0000],\n",
       "         [0.9000, 0.9000, 0.9000]]),\n",
       " tensor([[0.9000, 0.9000, 0.9000],\n",
       "         [0.8000, 0.8000, 0.8000]]),\n",
       " tensor([[0.8000, 0.8000, 0.8000],\n",
       "         [0.7000, 0.7000, 0.7000]]),\n",
       " tensor([[0.7000, 0.7000, 0.7000],\n",
       "         [0.6000, 0.6000, 0.6000]]),\n",
       " tensor([[0.6000, 0.6000, 0.6000],\n",
       "         [0.5000, 0.5000, 0.5000]]),\n",
       " tensor([[0.5000, 0.5000, 0.5000],\n",
       "         [0.4000, 0.4000, 0.4000]]),\n",
       " tensor([[0.4000, 0.4000, 0.4000],\n",
       "         [0.3000, 0.3000, 0.3000]]),\n",
       " tensor([[0.3000, 0.3000, 0.3000],\n",
       "         [0.2000, 0.2000, 0.2000]]),\n",
       " tensor([[0.2000, 0.2000, 0.2000],\n",
       "         [0.1000, 0.1000, 0.1000]]),\n",
       " tensor([[0.1000, 0.1000, 0.1000],\n",
       "         [0.0000, 0.0000, 0.0000]]))"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = GaussianDiffusion(noise_type='cosine', timesteps=10, device='cpu')\n",
    "g.get_sampling_timesteps(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "40d49a82-097c-4a78-bdaf-06b8fc3e82bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0015, 0.7292, 0.6209, 0.3540, 0.8060, 0.5618, 0.0910, 0.8585, 0.0087,\n",
       "        0.6487])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "sample_random_times(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4b02ad4d-d33d-4798-8e1a-1b5d34ed5eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exists(val):\n",
    "    return val is not None\n",
    "\n",
    "def maybe(fn):\n",
    "    @wraps(fn)\n",
    "    def inner(x):\n",
    "        if not exists(x):\n",
    "            return x\n",
    "        return fn(x)\n",
    "    return inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "cb9f7f90-368e-433f-937b-51bb45f081d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class GaussianDiffusionContinuousTimes(nn.Module):\n",
    "    def __init__(self, *, noise_schedule, timesteps):\n",
    "        super().__init__()\n",
    "        if noise_schedule == 'linear':\n",
    "            self.log_snr = beta_linear_log_snr\n",
    "        elif noise_schedule == \"cosine\":\n",
    "            self.log_snr = alpha_cosine_log_snr\n",
    "        else:\n",
    "            raise ValueError(f'invalid noise schedule {noise_schedule}')\n",
    "\n",
    "        self.num_timesteps = timesteps\n",
    "\n",
    "    def get_times(self, batch_size, noise_level, *, device):\n",
    "        return torch.full((batch_size,), noise_level, device = device, dtype = torch.long)\n",
    "\n",
    "    def sample_random_times(self, batch_size, max_thres = 0.999, *, device):\n",
    "        return torch.zeros((batch_size,), device = device).float().uniform_(0, max_thres)\n",
    "\n",
    "    def get_condition(self, times):\n",
    "        return maybe(self.log_snr)(times)\n",
    "\n",
    "    def get_sampling_timesteps(self, batch, *, device):\n",
    "        times = torch.linspace(1., 0., self.num_timesteps + 1, device = device)\n",
    "        times = repeat(times, 't -> b t', b = batch)\n",
    "        times = torch.stack((times[:, :-1], times[:, 1:]), dim = 0)\n",
    "        times = times.unbind(dim = -1)\n",
    "        return times\n",
    "\n",
    "    def q_posterior(self, x_start, x_t, t, *, t_next = None):\n",
    "        t_next = default(t_next, lambda: (t - 1. / self.num_timesteps).clamp(min = 0.))\n",
    "\n",
    "        \"\"\" https://openreview.net/attachment?id=2LdBqxc1Yv&name=supplementary_material \"\"\"\n",
    "        log_snr = self.log_snr(t)\n",
    "        log_snr_next = self.log_snr(t_next)\n",
    "        log_snr, log_snr_next = map(partial(right_pad_dims_to, x_t), (log_snr, log_snr_next))\n",
    "\n",
    "        alpha, sigma = log_snr_to_alpha_sigma(log_snr)\n",
    "        alpha_next, sigma_next = log_snr_to_alpha_sigma(log_snr_next)\n",
    "\n",
    "        # c - as defined near eq 33\n",
    "        c = -expm1(log_snr - log_snr_next)\n",
    "        posterior_mean = alpha_next * (x_t * (1 - c) / alpha + c * x_start)\n",
    "\n",
    "        # following (eq. 33)\n",
    "        posterior_variance = (sigma_next ** 2) * c\n",
    "        posterior_log_variance_clipped = log(posterior_variance, eps = 1e-20)\n",
    "        return posterior_mean, posterior_variance, posterior_log_variance_clipped\n",
    "\n",
    "    def q_sample(self, x_start, t, noise = None):\n",
    "        noise = default(noise, lambda: torch.randn_like(x_start))\n",
    "        log_snr = self.log_snr(t)\n",
    "        log_snr_padded_dim = right_pad_dims_to(x_start, log_snr)\n",
    "        alpha, sigma =  log_snr_to_alpha_sigma(log_snr_padded_dim)\n",
    "        return alpha * x_start + sigma * noise, log_snr\n",
    "\n",
    "    def predict_start_from_noise(self, x_t, t, noise):\n",
    "        log_snr = self.log_snr(t)\n",
    "        log_snr = right_pad_dims_to(x_t, log_snr)\n",
    "        alpha, sigma = log_snr_to_alpha_sigma(log_snr)\n",
    "        return (x_t - sigma * noise) / alpha.clamp(min = 1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c4669afd-8f98-4a41-840d-1b32fa04a2d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1.0000, 1.0000, 1.0000],\n",
       "         [0.9000, 0.9000, 0.9000]]),\n",
       " tensor([[0.9000, 0.9000, 0.9000],\n",
       "         [0.8000, 0.8000, 0.8000]]),\n",
       " tensor([[0.8000, 0.8000, 0.8000],\n",
       "         [0.7000, 0.7000, 0.7000]]),\n",
       " tensor([[0.7000, 0.7000, 0.7000],\n",
       "         [0.6000, 0.6000, 0.6000]]),\n",
       " tensor([[0.6000, 0.6000, 0.6000],\n",
       "         [0.5000, 0.5000, 0.5000]]),\n",
       " tensor([[0.5000, 0.5000, 0.5000],\n",
       "         [0.4000, 0.4000, 0.4000]]),\n",
       " tensor([[0.4000, 0.4000, 0.4000],\n",
       "         [0.3000, 0.3000, 0.3000]]),\n",
       " tensor([[0.3000, 0.3000, 0.3000],\n",
       "         [0.2000, 0.2000, 0.2000]]),\n",
       " tensor([[0.2000, 0.2000, 0.2000],\n",
       "         [0.1000, 0.1000, 0.1000]]),\n",
       " tensor([[0.1000, 0.1000, 0.1000],\n",
       "         [0.0000, 0.0000, 0.0000]]))"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from functools import partial, wraps\n",
    "b = GaussianDiffusionContinuousTimes(noise_schedule = 'linear', timesteps = 10)\n",
    "b.get_condition(torch.tensor(0.1))\n",
    "b.get_sampling_timesteps(3, device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "47808eb2-3182-4919-bbd5-3bd290b32570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1, 1])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def right_pad_dims_to(x, t):\n",
    "    padding_dims = x.ndim - t.ndim\n",
    "    print(x.ndim)\n",
    "    print(padding_dims)\n",
    "    if padding_dims <= 0:\n",
    "        return t\n",
    "    return t.view(*t.shape, *((1,) * padding_dims))\n",
    "\n",
    "hj = right_pad_dims_to(torch.full((3,4,5), 6), torch.full((3,), 5))\n",
    "hj.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8f327c-fdcc-4ac8-a182-2e8eac600833",
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_equal_x_dim(x, t):\n",
    "    padding_dims = x.ndim - t.ndim\n",
    "    \n",
    "    if padding_dims <= 0:\n",
    "        return t\n",
    "    return t.view(*t.shape, *((1,) * padding_dims))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e55106-0d02-47ac-8199-0aad5158ca41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def q_posterior(self, x_start, x_t, t, *, t_next = None):\n",
    "        t_next = default(t_next, lambda: (t - 1. / self.num_timesteps).clamp(min = 0.))\n",
    "\n",
    "        \"\"\" https://openreview.net/attachment?id=2LdBqxc1Yv&name=supplementary_material \"\"\"\n",
    "        log_snr = self.log_snr(t)\n",
    "        log_snr_next = self.log_snr(t_next)\n",
    "        log_snr, log_snr_next = map(partial(right_pad_dims_to, x_t), (log_snr, log_snr_next))\n",
    "\n",
    "        alpha, sigma = log_snr_to_alpha_sigma(log_snr)\n",
    "        alpha_next, sigma_next = log_snr_to_alpha_sigma(log_snr_next)\n",
    "\n",
    "        # c - as defined near eq 33\n",
    "        c = -expm1(log_snr - log_snr_next)\n",
    "        posterior_mean = alpha_next * (x_t * (1 - c) / alpha + c * x_start)\n",
    "\n",
    "        # following (eq. 33)\n",
    "        posterior_variance = (sigma_next ** 2) * c\n",
    "        posterior_log_variance_clipped = log(posterior_variance, eps = 1e-20)\n",
    "        return posterior_mean, posterior_variance, posterior_log_variance_clipped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03fc0c5-93df-4df2-8b64-0345e4ef4e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_snr_to_alpha_sigma(self, log_snr):\n",
    "    return torch.sqrt(torch.sigmoid(log_snr)), torch.sqrt(torch.sigmoid(-log_snr))\n",
    "\n",
    "def q_posterior(x_start, x_t, t, t_next):\n",
    "    \n",
    "    snr      = self.snr_func(t)\n",
    "    snr_next = self.snr_func(t_next)\n",
    "    \n",
    "    log_snr, log_snr_next = map(partial(t_equal_x_dim, x_t), (log_snr, log_snr_next))\n",
    "    \n",
    "    alpha, sigma           = log_snr_to_alpha_sigma(log_snr)\n",
    "    alpha_next, sigma_next = log_snr_to_alpha_sigma(log_snr_next)\n",
    "    \n",
    "    c      = 1 - torch.exp(log_snr - log_snr_next)\n",
    "    p_mean = alpha_next * (x_t * (1 - c) / alpha + c * x_start)\n",
    "    \n",
    "    p_variance     = (sigma_next ** 2) * c\n",
    "    p_log_variance = log(p_variance, eps = 1e-20)\n",
    "    p_log_variance = torch.log(p_variance.clamp(min = 1e-20))\n",
    "    \n",
    "    return p_mean, p_variance, p_log_variance\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "c3fc52c5-24cc-4353-b00b-717235e08389",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-53.5981)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = 1 - torch.exp(torch.tensor(4))\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "4be27ab6-9d33-4a9a-a4f8-bef8a7fe8d79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-53.5981)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-expm1(torch.tensor(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "1a33eb7e-6fd4-4d27-8887-3a3994c25b93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1.0000, 1.0000, 1.0000],\n",
       "         [0.9000, 0.9000, 0.9000]]),\n",
       " tensor([[0.9000, 0.9000, 0.9000],\n",
       "         [0.8000, 0.8000, 0.8000]]),\n",
       " tensor([[0.8000, 0.8000, 0.8000],\n",
       "         [0.7000, 0.7000, 0.7000]]),\n",
       " tensor([[0.7000, 0.7000, 0.7000],\n",
       "         [0.6000, 0.6000, 0.6000]]),\n",
       " tensor([[0.6000, 0.6000, 0.6000],\n",
       "         [0.5000, 0.5000, 0.5000]]),\n",
       " tensor([[0.5000, 0.5000, 0.5000],\n",
       "         [0.4000, 0.4000, 0.4000]]),\n",
       " tensor([[0.4000, 0.4000, 0.4000],\n",
       "         [0.3000, 0.3000, 0.3000]]),\n",
       " tensor([[0.3000, 0.3000, 0.3000],\n",
       "         [0.2000, 0.2000, 0.2000]]),\n",
       " tensor([[0.2000, 0.2000, 0.2000],\n",
       "         [0.1000, 0.1000, 0.1000]]),\n",
       " tensor([[0.1000, 0.1000, 0.1000],\n",
       "         [0.0000, 0.0000, 0.0000]]))"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt = b.get_sampling_timesteps(3, device='cpu')\n",
    "tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8572d8c4-2bdc-498b-86fe-44fd20cb7ac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sampling loop time step: 100%|██████████| 10/10 [00:00<00:00, 434.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1.]) tensor([0.9000, 0.9000, 0.9000])\n",
      "tensor([0.9000, 0.9000, 0.9000]) tensor([0.8000, 0.8000, 0.8000])\n",
      "tensor([0.8000, 0.8000, 0.8000]) tensor([0.7000, 0.7000, 0.7000])\n",
      "tensor([0.7000, 0.7000, 0.7000]) tensor([0.6000, 0.6000, 0.6000])\n",
      "tensor([0.6000, 0.6000, 0.6000]) tensor([0.5000, 0.5000, 0.5000])\n",
      "tensor([0.5000, 0.5000, 0.5000]) tensor([0.4000, 0.4000, 0.4000])\n",
      "tensor([0.4000, 0.4000, 0.4000]) tensor([0.3000, 0.3000, 0.3000])\n",
      "tensor([0.3000, 0.3000, 0.3000]) tensor([0.2000, 0.2000, 0.2000])\n",
      "tensor([0.2000, 0.2000, 0.2000]) tensor([0.1000, 0.1000, 0.1000])\n",
      "tensor([0.1000, 0.1000, 0.1000]) tensor([0., 0., 0.])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for times, times_next in tqdm(tt, desc = 'sampling loop time step', total = len(tt)):\n",
    "    print(times, times_next)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0895163-9728-4393-ba8f-52cc0a377422",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
