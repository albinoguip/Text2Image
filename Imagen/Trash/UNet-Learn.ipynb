{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5bbba2a7-f48e-4253-9aeb-1d2e6b5310c3",
   "metadata": {},
   "source": [
    "# TIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f27ba94-6f37-4f76-9479-63f7ad9bb80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "self.to_time_hiddens = nn.Sequential(\n",
    "            sinu_pos_emb,\n",
    "            nn.Linear(sinu_pos_emb_input_dim, time_cond_dim),\n",
    "            nn.SiLU()\n",
    "        )\n",
    "\n",
    "        self.to_time_cond = nn.Sequential(\n",
    "            nn.Linear(time_cond_dim, time_cond_dim)\n",
    "        )\n",
    "\n",
    "        # project to time tokens as well as time hiddens\n",
    "\n",
    "        self.to_time_tokens = nn.Sequential(\n",
    "            nn.Linear(time_cond_dim, cond_dim * num_time_tokens),\n",
    "            Rearrange('b (r d) -> b r d', r = num_time_tokens)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "880d85e8-a562-41aa-8cc6-306d5e9fc3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LearnedSinusoidalPosEmb(nn.Module):\n",
    "\n",
    "    def __init__(self, dim):\n",
    "        \n",
    "        super().__init__()\n",
    "        assert (dim % 2) == 0\n",
    "        self.weights = nn.Parameter(torch.randn(dim // 2))\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = rearrange(x, 'b -> b 1')    \n",
    "        f = x * rearrange(self.weights, 'd -> 1 d') \n",
    "        w = f * 2 * torch.pi\n",
    "        \n",
    "        return torch.cat((x, torch.sin(w), torch.cos(w)), dim = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5f9088ef-eb69-4e1b-a6a2-806f58bc869d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([-0.3285, -0.2634,  0.4139, -0.3833,  0.7469, -0.0939, -0.2985, -0.0953],\n",
      "       requires_grad=True)\n",
      "tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]])\n",
      "tensor([[ 1.0000, -0.8808, -0.9964,  0.5149, -0.6694, -0.9998, -0.5565, -0.9539,\n",
      "         -0.5636, -0.4735, -0.0844, -0.8573, -0.7429, -0.0197,  0.8309, -0.3000,\n",
      "          0.8260],\n",
      "        [ 1.0000, -0.8808, -0.9964,  0.5149, -0.6694, -0.9998, -0.5565, -0.9539,\n",
      "         -0.5636, -0.4735, -0.0844, -0.8573, -0.7429, -0.0197,  0.8309, -0.3000,\n",
      "          0.8260],\n",
      "        [ 1.0000, -0.8808, -0.9964,  0.5149, -0.6694, -0.9998, -0.5565, -0.9539,\n",
      "         -0.5636, -0.4735, -0.0844, -0.8573, -0.7429, -0.0197,  0.8309, -0.3000,\n",
      "          0.8260],\n",
      "        [ 1.0000, -0.8808, -0.9964,  0.5149, -0.6694, -0.9998, -0.5565, -0.9539,\n",
      "         -0.5636, -0.4735, -0.0844, -0.8573, -0.7429, -0.0197,  0.8309, -0.3000,\n",
      "          0.8260],\n",
      "        [ 1.0000, -0.8808, -0.9964,  0.5149, -0.6694, -0.9998, -0.5565, -0.9539,\n",
      "         -0.5636, -0.4735, -0.0844, -0.8573, -0.7429, -0.0197,  0.8309, -0.3000,\n",
      "          0.8260],\n",
      "        [ 1.0000, -0.8808, -0.9964,  0.5149, -0.6694, -0.9998, -0.5565, -0.9539,\n",
      "         -0.5636, -0.4735, -0.0844, -0.8573, -0.7429, -0.0197,  0.8309, -0.3000,\n",
      "          0.8260],\n",
      "        [ 1.0000, -0.8808, -0.9964,  0.5149, -0.6694, -0.9998, -0.5565, -0.9539,\n",
      "         -0.5636, -0.4735, -0.0844, -0.8573, -0.7429, -0.0197,  0.8309, -0.3000,\n",
      "          0.8260],\n",
      "        [ 1.0000, -0.8808, -0.9964,  0.5149, -0.6694, -0.9998, -0.5565, -0.9539,\n",
      "         -0.5636, -0.4735, -0.0844, -0.8573, -0.7429, -0.0197,  0.8309, -0.3000,\n",
      "          0.8260]], grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 18])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from einops import rearrange\n",
    "import math\n",
    "\n",
    "lspe = LearnedSinusoidalPosEmb(16)\n",
    "x = torch.ones(8)\n",
    "print(lspe.weights)\n",
    "lspe(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50e7ac9-8ebd-4efb-bc3b-6d69be84c157",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Swish(nn.Module):\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x * torch.sigmoid(x)\n",
    "    \n",
    "class LearnedSinusoidalPosEmb(nn.Module):\n",
    "\n",
    "    def __init__(self, dim):\n",
    "        \n",
    "        super().__init__()\n",
    "        assert (dim % 2) == 0\n",
    "        self.weights = nn.Parameter(torch.randn(dim // 2))\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = rearrange(x, 'b -> b 1')    \n",
    "        f = x * rearrange(self.weights, 'd -> 1 d') \n",
    "        w = f * 2 * torch.pi\n",
    "        \n",
    "        return torch.cat((x, torch.sin(w), torch.cos(w)), dim = -1)\n",
    "\n",
    "class TimeConditioning(nn.Module):\n",
    "    \n",
    "    def __init__(self, unet_dim, time_embedding_dim=16, num_time_tokens = 2):\n",
    "        super(TimeConditioning, self).__init__()\n",
    "        \n",
    "        self.to_time_hiddens = nn.Sequential(LearnedSinusoidalPosEmb(time_embedding_dim)\n",
    "                                             nn.Linear(time_embedding_dim+1, unet_dim*4),\n",
    "                                             nn.Swish())\n",
    "\n",
    "        self.to_time_cond = nn.Linear(unet_dim*4, unet_dim*4)\n",
    "\n",
    "        self.to_time_tokens = nn.Sequential(nn.Linear(unet_dim*4, unet_dim * num_time_tokens),\n",
    "                                            Rearrange('b (r d) -> b r d', r = num_time_tokens))\n",
    "        \n",
    "        self.norm_cond = nn.LayerNorm(cond_dim)\n",
    "        \n",
    "    def forward(self, time):\n",
    "        \n",
    "        time_hiddens = self.to_time_hiddens(time)\n",
    "        \n",
    "        time_tokens = self.to_time_tokens(time_hiddens)\n",
    "        t           = self.to_time_cond(time_hiddens)\n",
    "        \n",
    "        return t, time_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "834fc482-0b23-4408-ae8d-11ced9f9b3c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([-0.1929,  1.2791, -0.5375,  1.5420,  2.4278,  1.8879, -0.4106,  0.3239],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "nn.Parameter(torch.randn(16 // 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4e20eb4-acc8-4cf9-9f7c-28b7ff917863",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.4047, -1.2444, -1.2889, -0.4955,  0.7217, -1.7086, -0.1643,  1.3201],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn(16 // 2, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98060989-dabf-4d52-9aa6-e325db77b0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PerceiverAttention(nn.Module):\n",
    "    def __init__(self, *, dim, dim_head = 64, heads = 8):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.scale = dim_head ** -0.5\n",
    "        self.heads = heads\n",
    "        inner_dim = dim_head * heads\n",
    "\n",
    "        self.norm         = nn.LayerNorm(dim)\n",
    "        self.norm_latents = nn.LayerNorm(dim)\n",
    "\n",
    "        self.Q  = nn.Linear(dim, inner_dim, bias = False)\n",
    "        self.KV = nn.Linear(dim, inner_dim * 2, bias = False)\n",
    "\n",
    "        self.output_layer = nn.Sequential(nn.Linear(inner_dim, dim, bias = False), nn.LayerNorm(dim))\n",
    "\n",
    "    def forward(self, x, latents, mask = None):\n",
    "        \n",
    "        x       = self.norm(x)\n",
    "        latents = self.norm_latents(latents)\n",
    "        kv      = torch.cat((x, latents), dim = -2)\n",
    "\n",
    "        b, h = x.shape[0], self.heads\n",
    "\n",
    "        queries      = self.Q(latents)        \n",
    "        keys, values = self.KV(kv_input).chunk(2, dim = -1)\n",
    "\n",
    "        q, k, v = rearrange_many((q, k, v), 'b n (h d) -> b h n d', h = h)\n",
    "\n",
    "        q = q * self.scale\n",
    "\n",
    "        # attention\n",
    "\n",
    "        sim = einsum('... i d, ... j d  -> ... i j', q, k)\n",
    "\n",
    "        if exists(mask):\n",
    "            max_neg_value = -torch.finfo(sim.dtype).max\n",
    "            mask = F.pad(mask, (0, latents.shape[-2]), value = True)\n",
    "            mask = rearrange(mask, 'b j -> b 1 1 j')\n",
    "            sim = sim.masked_fill(~mask, max_neg_value)\n",
    "\n",
    "        attn = sim.softmax(dim = -1, dtype = torch.float32)\n",
    "\n",
    "        out = einsum('... i j, ... j d -> ... i d', attn, v)\n",
    "        out = rearrange(out, 'b h n d -> b n (h d)', h = h)\n",
    "        return self.to_out(out)\n",
    "\n",
    "    \n",
    "class PerceiverResampler(nn.Module):\n",
    "    def __init__(self, unet_dim, depth=2, dim_head = 64, heads = 8, num_latents = 32,\n",
    "                 num_latents_mean_pooled = 4, max_seq_len = 512, ff_mult = 4):\n",
    "        \n",
    "        super(PerceiverResampler, self).__init__()\n",
    "        \n",
    "        self.unet_dim = unet_dim\n",
    "                \n",
    "        self.pos_emb = nn.Embedding(max_seq_len, dim)\n",
    "        self.latents = nn.Parameter(torch.randn(num_latents, dim))\n",
    "\n",
    "        self.to_latents_from_mean_pooled_seq = None\n",
    "\n",
    "        self.to_latents_from_mean_pooled_seq = nn.Sequential(\n",
    "                # LayerNorm(dim),\n",
    "                nn.Linear(unet_dim, unet_dim * num_latents_mean_pooled),\n",
    "                Rearrange('b (n d) -> b n d', n = num_latents_mean_pooled))\n",
    "\n",
    "        self.layers = nn.ModuleList([])\n",
    "        for _ in range(depth):\n",
    "            self.layers.append(nn.ModuleList([PerceiverAttention(dim = dim, dim_head = dim_head, heads = heads),\n",
    "                                              FeedForward(dim = dim, mult = ff_mult)]))\n",
    "\n",
    "    def forward(self, x, mask = None):\n",
    "        n, device = x.shape[1], x.device\n",
    "        pos_emb = self.pos_emb(torch.arange(n, device = device))\n",
    "\n",
    "        x_with_pos = x + pos_emb\n",
    "\n",
    "        latents = repeat(self.latents, 'n d -> b n d', b = x.shape[0])\n",
    "        \n",
    "        F.layer_norm(x, x.shape[-1:], nn.Parameter(torch.ones(self.unet_dim)), torch.zeros(self.unet_dim))\n",
    "\n",
    "        if exists(self.to_latents_from_mean_pooled_seq):\n",
    "            meanpooled_seq = masked_mean(x, dim = 1, mask = torch.ones(x.shape[:2], device = x.device, dtype = torch.bool))\n",
    "            meanpooled_latents = self.to_latents_from_mean_pooled_seq(meanpooled_seq)\n",
    "            latents = torch.cat((meanpooled_latents, latents), dim = -2)\n",
    "\n",
    "        for attn, ff in self.layers:\n",
    "            latents = attn(x_with_pos, latents, mask = mask) + latents\n",
    "            latents = ff(latents) + latents\n",
    "\n",
    "        return latents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1efe68-4925-4e55-a003-70d02b6a78a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextConditioning(nn.Module):\n",
    "    \n",
    "    def __init__(self, unet_dim, text_embedding_dim):\n",
    "        super(TextConditioning, self).__init__()\n",
    "        \n",
    "        self.text_to_cond  = nn.Linear(text_embedding_dim, unet_dim)\n",
    "        self.attn_pool     = PerceiverResampler(dim = cond_dim, depth = 2, dim_head = attn_dim_head, heads = attn_heads, num_latents = attn_pool_num_latents)\n",
    "        self.non_attn_cond = nn.Sequential(nn.LayerNorm(unet_dim),\n",
    "                                           nn.Linear(unet_dim, unet_dim*4),\n",
    "                                           Swish(),\n",
    "                                           nn.Linear(unet_dim*4, unet_dim*4))\n",
    "        \n",
    "    def forward(self, text_embeds, text_mask):\n",
    "        \n",
    "        text_tokens = self.text_to_cond(text_embeds)[:, :self.max_text_len]\n",
    "\n",
    "        \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
